# -*- coding: utf-8 -*-
"""
é¡¹ç›®3ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«
====================
è¿™æ˜¯ä¸€ä¸ªå›¾åƒåˆ†ç±»é¡¹ç›®ï¼Œè¯†åˆ«0-9çš„æ‰‹å†™æ•°å­—ã€‚

é¡¹ç›®ç›®æ ‡ï¼š
- åŠ è½½æ‰‹å†™æ•°å­—æ•°æ®é›†
- è®­ç»ƒåˆ†ç±»æ¨¡å‹
- å¯è§†åŒ–æ•°å­—å›¾åƒ
- æµ‹è¯•è¯†åˆ«æ•ˆæœ

è¿è¡Œæ–¹å¼ï¼š
    python digit_recognition.py
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import os

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤ºï¼ˆå…¼å®¹ä¸åŒç³»ç»Ÿï¼‰
import platform
if platform.system() == 'Windows':
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun']
elif platform.system() == 'Darwin':  # Mac
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC']
else:  # Linux
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def load_data():
    """
    åŠ è½½æ‰‹å†™æ•°å­—æ•°æ®é›†

    è¿”å›:
        tuple: (å›¾åƒæ•°æ®, æ ‡ç­¾, å›¾åƒæ•°ç»„å½¢å¼)

    æ•°æ®è¯´æ˜:
        - 1797ä¸ªæ‰‹å†™æ•°å­—æ ·æœ¬
        - æ¯ä¸ªæ•°å­—æ˜¯8x8åƒç´ çš„ç°åº¦å›¾åƒ
        - æ ‡ç­¾æ˜¯0-9çš„æ•°å­—
    """
    print("=" * 50)
    print("ğŸ”¢ æ‰‹å†™æ•°å­—è¯†åˆ«é¡¹ç›®")
    print("=" * 50)
    print()

    print("ã€æ­¥éª¤1ï¼šåŠ è½½æ•°æ®ã€‘")

    # åŠ è½½sklearnå†…ç½®çš„æ‰‹å†™æ•°å­—æ•°æ®é›†
    digits = datasets.load_digits()

    X = digits.data          # ç‰¹å¾æ•°æ®ï¼ˆ64ä¸ªåƒç´ å€¼ï¼‰
    y = digits.target        # æ ‡ç­¾ï¼ˆ0-9ï¼‰
    images = digits.images   # å›¾åƒå½¢å¼ï¼ˆ8x8çŸ©é˜µï¼‰

    print(f"  æ ·æœ¬æ•°é‡ï¼š{len(X)}")
    print(f"  å›¾åƒå°ºå¯¸ï¼š{images[0].shape}ï¼ˆ8x8åƒç´ ï¼‰")
    print(f"  ç‰¹å¾æ•°é‡ï¼š{X.shape[1]}ï¼ˆ64ä¸ªåƒç´ å€¼ï¼‰")
    print(f"  ç±»åˆ«æ•°é‡ï¼š{len(np.unique(y))}ï¼ˆæ•°å­—0-9ï¼‰")
    print()

    return X, y, images


def explore_data(X, y, images):
    """
    æ¢ç´¢å’Œå¯è§†åŒ–æ•°æ®

    å‚æ•°:
        X: ç‰¹å¾æ•°æ®
        y: æ ‡ç­¾
        images: å›¾åƒæ•°ç»„

    åŠŸèƒ½:
        - æ˜¾ç¤ºæ•°å­—å›¾åƒç¤ºä¾‹
        - ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
    """
    print("ã€æ­¥éª¤2ï¼šæ¢ç´¢æ•°æ®ã€‘")

    # æ˜¾ç¤ºæ•°å­—å›¾åƒç¤ºä¾‹
    print("  æ•°å­—å›¾åƒç¤ºä¾‹ï¼š")

    fig, axes = plt.subplots(2, 5, figsize=(12, 5))

    for i, ax in enumerate(axes.flat):
        # æ‰¾åˆ°å½“å‰æ•°å­—çš„ç¬¬ä¸€ä¸ªæ ·æœ¬
        idx = np.where(y == i)[0][0]
        ax.imshow(images[idx], cmap='gray')
        ax.set_title(f'æ•°å­— {i}')
        ax.axis('off')

    plt.tight_layout()

    output_dir = '/mnt/c/dev/python/qqstudy/ai_intro'
    plt.savefig(os.path.join(output_dir, 'digit_samples.png'), dpi=100)
    print("  âœ… æ ·æœ¬å›¾åƒå·²ä¿å­˜åˆ°ï¼šdigit_samples.png")
    plt.close()
    print()

    # æ˜¾ç¤ºæ›´å¤šæ ·æœ¬
    print("  æ˜¾ç¤ºå‰20ä¸ªè®­ç»ƒæ ·æœ¬ï¼š")

    fig, axes = plt.subplots(2, 10, figsize=(15, 3))

    for i in range(20):
        ax = axes[i // 10, i % 10]
        ax.imshow(images[i], cmap='gray')
        ax.set_title(f'{y[i]}')
        ax.axis('off')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'digit_first20.png'), dpi=100)
    print("  âœ… å‰20ä¸ªæ ·æœ¬å·²ä¿å­˜åˆ°ï¼šdigit_first20.png")
    plt.close()
    print()

    # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
    print("  å„æ•°å­—æ•°é‡ï¼š")
    unique, counts = np.unique(y, return_counts=True)
    for digit, count in zip(unique, counts):
        bar = 'â–ˆ' * (count // 5)
        print(f"    æ•°å­— {digit}: {count:3d} {bar}")
    print()


def train_model(X, y, test_size=0.3, model_type='knn'):
    """
    è®­ç»ƒæ•°å­—è¯†åˆ«æ¨¡å‹

    å‚æ•°:
        X: ç‰¹å¾æ•°æ®
        y: æ ‡ç­¾
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        model_type: æ¨¡å‹ç±»å‹ï¼ˆ'knn' æˆ– 'svm'ï¼‰

    è¿”å›:
        tuple: (æ¨¡å‹, X_train, X_test, y_train, y_test)
    """
    print("ã€æ­¥éª¤3ï¼šè®­ç»ƒæ¨¡å‹ã€‘")

    # åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )

    print(f"  è®­ç»ƒé›†å¤§å°ï¼š{len(X_train)}")
    print(f"  æµ‹è¯•é›†å¤§å°ï¼š{len(X_test)}")
    print()

    # é€‰æ‹©æ¨¡å‹
    if model_type == 'knn':
        print("  ä½¿ç”¨ç®—æ³•ï¼šKè¿‘é‚» (KNN, K=5)")
        model = KNeighborsClassifier(n_neighbors=5)
    else:
        print("  ä½¿ç”¨ç®—æ³•ï¼šæ”¯æŒå‘é‡æœº (SVM)")
        model = SVC(kernel='rbf', gamma=0.001)

    # è®­ç»ƒ
    model.fit(X_train, y_train)

    print("  âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print()

    return model, X_train, X_test, y_train, y_test


def evaluate_model(model, X_test, y_test):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½

    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        X_test: æµ‹è¯•ç‰¹å¾
        y_test: æµ‹è¯•æ ‡ç­¾

    åŠŸèƒ½:
        - è®¡ç®—å‡†ç¡®ç‡
        - æ˜¾ç¤ºæ··æ·†çŸ©é˜µ
        - åˆ†æé”™è¯¯åˆ†ç±»
    """
    print("ã€æ­¥éª¤4ï¼šè¯„ä¼°æ¨¡å‹ã€‘")

    # é¢„æµ‹
    y_pred = model.predict(X_test)

    # å‡†ç¡®ç‡
    accuracy = accuracy_score(y_test, y_pred)
    print(f"  å‡†ç¡®ç‡ï¼š{accuracy:.2%}")
    print()

    # åˆ†ç±»æŠ¥å‘Š
    print("  åˆ†ç±»æŠ¥å‘Šï¼š")
    print(classification_report(y_test, y_pred))
    print()

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(10, 8))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.colorbar()
    tick_marks = np.arange(10)
    plt.xticks(tick_marks, range(10))
    plt.yticks(tick_marks, range(10))

    # åœ¨æ ¼å­ä¸­æ˜¾ç¤ºæ•°å­—
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], 'd'),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('çœŸå®æ•°å­—')
    plt.xlabel('é¢„æµ‹æ•°å­—')
    plt.tight_layout()

    output_dir = '/mnt/c/dev/python/qqstudy/ai_intro'
    plt.savefig(os.path.join(output_dir, 'digit_confusion_matrix.png'), dpi=100)
    print("  âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°ï¼šdigit_confusion_matrix.png")
    plt.close()
    print()

    # åˆ†æé”™è¯¯åˆ†ç±»
    errors = np.where(y_pred != y_test)[0]
    print(f"  é”™è¯¯åˆ†ç±»æ•°é‡ï¼š{len(errors)} / {len(y_test)}")

    if len(errors) > 0:
        print("  éƒ¨åˆ†é”™è¯¯ç¤ºä¾‹ï¼š")
        # é‡å¡‘æµ‹è¯•é›†å›¾åƒ
        test_images = X_test.reshape(-1, 8, 8)

        fig, axes = plt.subplots(2, 5, figsize=(12, 5))

        for i, ax in enumerate(axes.flat):
            if i < len(errors):
                idx = errors[i]
                ax.imshow(test_images[idx], cmap='gray')
                ax.set_title(f'çœŸå®:{y_test[idx]}, é¢„æµ‹:{y_pred[idx]}')
            ax.axis('off')

        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'digit_errors.png'), dpi=100)
        print("  âœ… é”™è¯¯åˆ†ç±»ç¤ºä¾‹å·²ä¿å­˜åˆ°ï¼šdigit_errors.png")
        plt.close()
    print()


def predict_samples(model, X_test, y_test, n_samples=10):
    """
    é¢„æµ‹å¹¶å¯è§†åŒ–æ ·æœ¬

    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        X_test: æµ‹è¯•ç‰¹å¾
        y_test: æµ‹è¯•æ ‡ç­¾
        n_samples: æ˜¾ç¤ºçš„æ ·æœ¬æ•°é‡
    """
    print("ã€æ­¥éª¤5ï¼šé¢„æµ‹æ ·æœ¬ã€‘")

    # éšæœºé€‰æ‹©ä¸€äº›æ ·æœ¬
    np.random.seed(42)
    indices = np.random.choice(len(X_test), n_samples, replace=False)

    # é¢„æµ‹
    predictions = model.predict(X_test[indices])
    actuals = y_test[indices]

    # å¯è§†åŒ–
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))

    for i, ax in enumerate(axes.flat):
        if i < n_samples:
            img = X_test[indices[i]].reshape(8, 8)
            ax.imshow(img, cmap='gray')

            correct = 'âœ“' if predictions[i] == actuals[i] else 'âœ—'
            ax.set_title(f'é¢„æµ‹:{predictions[i]} å®é™…:{actuals[i]} {correct}')
        ax.axis('off')

    plt.tight_layout()

    output_dir = '/mnt/c/dev/python/qqstudy/ai_intro'
    plt.savefig(os.path.join(output_dir, 'digit_predictions.png'), dpi=100)
    print("  âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°ï¼šdigit_predictions.png")
    plt.close()
    print()

    # æ‰“å°ç»“æœ
    print("  é¢„æµ‹ç»“æœï¼š")
    correct_count = 0
    for i in range(n_samples):
        match = "âœ“ æ­£ç¡®" if predictions[i] == actuals[i] else "âœ— é”™è¯¯"
        print(f"    æ ·æœ¬{i+1}: é¢„æµ‹={predictions[i]}, å®é™…={actuals[i]} â†’ {match}")
        if predictions[i] == actuals[i]:
            correct_count += 1
    print(f"\n  æ­£ç¡®ç‡ï¼š{correct_count}/{n_samples}")
    print()


def compare_models(X, y):
    """
    æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½

    å‚æ•°:
        X: ç‰¹å¾æ•°æ®
        y: æ ‡ç­¾

    åŠŸèƒ½:
        - è®­ç»ƒKNNå’ŒSVM
        - æ¯”è¾ƒå‡†ç¡®ç‡
    """
    print("ã€æ­¥éª¤6ï¼šæ¯”è¾ƒä¸åŒæ¨¡å‹ã€‘")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    models = {
        'KNN (K=1)': KNeighborsClassifier(n_neighbors=1),
        'KNN (K=3)': KNeighborsClassifier(n_neighbors=3),
        'KNN (K=5)': KNeighborsClassifier(n_neighbors=5),
        'KNN (K=7)': KNeighborsClassifier(n_neighbors=7),
        'SVM': SVC(kernel='rbf', gamma=0.001),
    }

    results = {}

    print("  è®­ç»ƒå’Œè¯„ä¼°å„æ¨¡å‹...")
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        results[name] = accuracy
        print(f"    {name}: {accuracy:.2%}")
    print()

    # å¯è§†åŒ–æ¯”è¾ƒ
    plt.figure(figsize=(10, 5))
    names = list(results.keys())
    accuracies = list(results.values())
    colors = ['blue', 'blue', 'blue', 'blue', 'green']

    bars = plt.bar(names, accuracies, color=colors)
    plt.ylim(0.9, 1.0)
    plt.ylabel('å‡†ç¡®ç‡')
    plt.title('ä¸åŒæ¨¡å‹å‡†ç¡®ç‡æ¯”è¾ƒ')

    # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
    for bar, acc in zip(bars, accuracies):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,
                f'{acc:.2%}', ha='center', va='bottom')

    plt.tight_layout()

    output_dir = '/mnt/c/dev/python/qqstudy/ai_intro'
    plt.savefig(os.path.join(output_dir, 'digit_model_comparison.png'), dpi=100)
    print("  âœ… æ¨¡å‹æ¯”è¾ƒå›¾å·²ä¿å­˜åˆ°ï¼šdigit_model_comparison.png")
    plt.close()
    print()


def main():
    """
    ä¸»ç¨‹åºå…¥å£

    æ‰§è¡Œå®Œæ•´çš„æ•°å­—è¯†åˆ«æµç¨‹ï¼š
    1. åŠ è½½æ•°æ®
    2. æ¢ç´¢æ•°æ®
    3. è®­ç»ƒæ¨¡å‹
    4. è¯„ä¼°æ¨¡å‹
    5. é¢„æµ‹æ ·æœ¬
    6. æ¯”è¾ƒä¸åŒæ¨¡å‹
    """
    # 1. åŠ è½½æ•°æ®
    X, y, images = load_data()

    # 2. æ¢ç´¢æ•°æ®
    explore_data(X, y, images)

    # 3. è®­ç»ƒæ¨¡å‹
    model, X_train, X_test, y_train, y_test = train_model(X, y)

    # 4. è¯„ä¼°æ¨¡å‹
    evaluate_model(model, X_test, y_test)

    # 5. é¢„æµ‹æ ·æœ¬
    predict_samples(model, X_test, y_test)

    # 6. æ¯”è¾ƒæ¨¡å‹
    compare_models(X, y)

    print("=" * 50)
    print("ğŸ‰ é¡¹ç›®å®Œæˆï¼")
    print("=" * 50)
    print()
    print("ä½ å­¦ä¼šäº†ï¼š")
    print("  âœ“ åŠ è½½å’Œå¯è§†åŒ–å›¾åƒæ•°æ®")
    print("  âœ“ è®­ç»ƒæ•°å­—è¯†åˆ«æ¨¡å‹")
    print("  âœ“ åˆ†ææ··æ·†çŸ©é˜µ")
    print("  âœ“ æ¯”è¾ƒä¸åŒæ¨¡å‹æ€§èƒ½")
    print()


if __name__ == "__main__":
    main()
