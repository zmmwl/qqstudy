# -*- coding: utf-8 -*-
"""
AIå…¥é—¨é€Ÿæˆæ•™ç¨‹ - é€‚åˆåˆä¸­ç”Ÿå­¦ä¹ 
=====================================
ä½œè€…ï¼šAIæ•™å­¦å›¢é˜Ÿ
ç›®æ ‡ï¼š2å°æ—¶æŒæ¡AIåŸºç¡€æ¦‚å¿µå’Œå®è·µ

è¿™ä¸ªæ•™ç¨‹å°†å¸¦ä½ ä»é›¶å¼€å§‹å­¦ä¹ äººå·¥æ™ºèƒ½ï¼
æ¯ä¸ªç« èŠ‚éƒ½æœ‰è¯¦ç»†çš„è§£é‡Šå’Œå¯ä»¥è¿è¡Œçš„ä»£ç ã€‚
"""

# ============================================
# å‡†å¤‡å·¥ä½œï¼šå®‰è£…å¿…è¦çš„åº“
# ============================================
"""
åœ¨è¿è¡Œæœ¬æ•™ç¨‹å‰ï¼Œè¯·å…ˆå®‰è£…ä»¥ä¸‹åº“ï¼š
pip install scikit-learn numpy pandas matplotlib

å¦‚æœå®‰è£…å¤ªæ…¢ï¼Œå¯ä»¥ä½¿ç”¨å›½å†…é•œåƒï¼š
pip install scikit-learn numpy pandas matplotlib -i https://pypi.tuna.tsinghua.edu.cn/simple
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, mean_squared_error, r2_score

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤ºï¼ˆå…¼å®¹ä¸åŒç³»ç»Ÿï¼‰
try:
    # Windows
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun']
except:
    pass
try:
    # Linux/Mac
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'DejaVu Sans']
except:
    pass
plt.rcParams['axes.unicode_minus'] = False    # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

print("=" * 60)
print("ğŸ‰ æ¬¢è¿æ¥åˆ°AIå…¥é—¨é€Ÿæˆæ•™ç¨‹ï¼")
print("=" * 60)
print()


# ============================================
# ç¬¬1èŠ‚ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ
# ============================================
def lesson_1_what_is_ai():
    """
    ç¬¬1èŠ‚ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ
    ========================

    å­¦ä¹ ç›®æ ‡ï¼š
    - ç†è§£äººå·¥æ™ºèƒ½çš„åŸºæœ¬æ¦‚å¿µ
    - äº†è§£AIåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„åº”ç”¨
    - çŸ¥é“AIçš„ä¸»è¦åˆ†ç±»

    ã€ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿã€‘

    æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœç”µè„‘èƒ½åƒäººä¸€æ ·ï¼š
    - çœ‹ç…§ç‰‡è®¤å‡ºä½ çš„æœ‹å‹ â†’ è®¡ç®—æœºè§†è§‰
    - å¬æ‡‚ä½ è¯´çš„è¯ â†’ è¯­éŸ³è¯†åˆ«
    - è¯»æ–‡ç« ç†è§£å†…å®¹ â†’ è‡ªç„¶è¯­è¨€å¤„ç†
    - ä¸‹å›´æ£‹èµ¢è¿‡äººç±» â†’ æ¸¸æˆAI

    è¿™å°±æ˜¯äººå·¥æ™ºèƒ½ï¼ç®€å•è¯´å°±æ˜¯ï¼šè®©æœºå™¨å˜å¾—"èªæ˜"ï¼Œèƒ½åƒäººä¸€æ ·æ€è€ƒå’Œåšäº‹ã€‚

    ã€AIçš„åˆ†ç±»ã€‘

    1. å¼±äººå·¥æ™ºèƒ½ï¼ˆç°åœ¨ï¼‰
       - åªèƒ½åšä¸€ä»¶äº‹ï¼Œä½†åšå¾—å¾ˆå¥½
       - ä¾‹å­ï¼šAlphaGoåªä¼šä¸‹å›´æ£‹ï¼Œä¸ä¼šåšé¥­

    2. å¼ºäººå·¥æ™ºèƒ½ï¼ˆæœªæ¥ï¼‰
       - åƒäººä¸€æ ·ï¼Œä»€ä¹ˆéƒ½èƒ½å­¦
       - ç›®å‰è¿˜æ²¡æœ‰å®ç°

    ã€AIçš„åº”ç”¨ã€‘

    - æ‰‹æœºï¼šäººè„¸è§£é”ã€è¯­éŸ³åŠ©æ‰‹
    - æ¸¸æˆï¼šNPCæ•Œäººã€æ¨èç³»ç»Ÿ
    - åŒ»ç–—ï¼šè¾…åŠ©è¯Šæ–­
    - äº¤é€šï¼šè‡ªåŠ¨é©¾é©¶
    - è´­ç‰©ï¼šå•†å“æ¨è
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬1èŠ‚ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
    print("=" * 60)
    print()

    # AIåº”ç”¨ç¤ºä¾‹ï¼šç®€å•çš„è§„åˆ™åŒ¹é…
    print("ğŸ¤– è®©æˆ‘ä»¬æ¥ä½“éªŒä¸€ä¸ªç®€å•çš„AIç¨‹åºï¼")
    print("è¿™æ˜¯ä¸€ä¸ª'æ™ºèƒ½é—®ç­”æœºå™¨äºº'ï¼š")
    print()

    # å®šä¹‰é—®é¢˜å’Œç­”æ¡ˆçš„å¯¹åº”å…³ç³»ï¼ˆçŸ¥è¯†åº“ï¼‰
    qa_dict = {
        "ä½ å¥½": "ä½ å¥½ï¼æˆ‘æ˜¯AIå°åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼",
        "ä½ å«ä»€ä¹ˆ": "æˆ‘æ˜¯AIå…¥é—¨æ•™ç¨‹çš„æ¼”ç¤ºæœºå™¨äºº",
        "ä»€ä¹ˆæ˜¯ai": "AIå°±æ˜¯äººå·¥æ™ºèƒ½ï¼Œè®©æœºå™¨å˜å¾—èªæ˜",
        "ä»Šå¤©å¤©æ°”": "æŠ±æ­‰ï¼Œæˆ‘è¿˜æ²¡æœ‰è”ç½‘ï¼Œä¸èƒ½æŸ¥è¯¢å¤©æ°”",
        "å†è§": "å†è§ï¼ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼"
    }

    def simple_ai_chat(question):
        """
        ç®€å•çš„é—®ç­”AI

        å‚æ•°:
            question: ç”¨æˆ·çš„é—®é¢˜ï¼ˆå­—ç¬¦ä¸²ï¼‰

        è¿”å›:
            å›ç­”å­—ç¬¦ä¸²

        å·¥ä½œåŸç†:
            è¿™æ˜¯ä¸€ä¸ªåŸºäºè§„åˆ™çš„AIï¼Œå®ƒé€šè¿‡åŒ¹é…å…³é”®è¯æ¥å›ç­”é—®é¢˜ã€‚
            è™½ç„¶ç®€å•ï¼Œä½†å®ƒå±•ç¤ºäº†AIçš„æ ¸å¿ƒæ€æƒ³ï¼šè¾“å…¥â†’å¤„ç†â†’è¾“å‡º
        """
        question = question.lower()  # è½¬å°å†™
        for key, answer in qa_dict.items():
            if key in question:
                return answer
        return "è¿™ä¸ªé—®é¢˜æˆ‘è¿˜ä¸æ‡‚ï¼Œä½†æˆ‘æ­£åœ¨å­¦ä¹ ï¼"

    # æ¼”ç¤ºå¯¹è¯
    test_questions = ["ä½ å¥½å‘€", "ä»€ä¹ˆæ˜¯AIï¼Ÿ", "ä½ å‡ å²äº†", "å†è§"]
    for q in test_questions:
        print(f"  ğŸ‘¤ é—®ï¼š{q}")
        print(f"  ğŸ¤– ç­”ï¼š{simple_ai_chat(q)}")
        print()

    print("ğŸ’¡ å°çŸ¥è¯†ï¼šè¿™ä¸ªç®€å•çš„AIä½¿ç”¨'è§„åˆ™åŒ¹é…'æ–¹æ³•")
    print("   ç°ä»£AIä¼šä½¿ç”¨æ›´å¤æ‚çš„æ–¹æ³•ï¼Œæ¯”å¦‚æœºå™¨å­¦ä¹ ï¼")
    print()
    input("æŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€èŠ‚...")
    print()


# ============================================
# ç¬¬2èŠ‚ï¼šæœºå™¨å­¦ä¹ åŸºç¡€
# ============================================
def lesson_2_ml_basics():
    """
    ç¬¬2èŠ‚ï¼šæœºå™¨å­¦ä¹ åŸºç¡€
    ====================

    å­¦ä¹ ç›®æ ‡ï¼š
    - ç†è§£æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ
    - æŒæ¡è®­ç»ƒæ•°æ®ã€ç‰¹å¾ã€æ ‡ç­¾çš„å«ä¹‰
    - äº†è§£æœºå™¨å­¦ä¹ çš„å·¥ä½œæµç¨‹

    ã€ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿã€‘

    ä¼ ç»Ÿç¼–ç¨‹ï¼šäººç±»å†™è§„åˆ™ â†’ ç¨‹åºæ‰§è¡Œ
    æœºå™¨å­¦ä¹ ï¼šç»™ç¨‹åºæ•°æ® â†’ ç¨‹åºè‡ªå·±æ‰¾è§„å¾‹

    ä¾‹å­ï¼šè¯†åˆ«çŒ«å’Œç‹—
    - ä¼ ç»Ÿï¼šäººç±»æè¿°"çŒ«æœ‰å°–è€³æœµã€èƒ¡é¡»..."
    - æœºå™¨å­¦ä¹ ï¼šç»™ç¨‹åºçœ‹1000å¼ çŒ«å’Œç‹—çš„ç…§ç‰‡ï¼Œè®©å®ƒè‡ªå·±å­¦

    ã€æ ¸å¿ƒæ¦‚å¿µã€‘

    1. è®­ç»ƒæ•°æ®ï¼ˆTraining Dataï¼‰
       - ç”¨æ¥æ•™AIçš„"æ•™æ"
       - å°±åƒå­¦ç”Ÿçš„è¯¾æœ¬

    2. ç‰¹å¾ï¼ˆFeaturesï¼‰
       - æè¿°äº‹ç‰©çš„å±æ€§
       - æ¯”å¦‚ï¼šè‹¹æœçš„é¢œè‰²ã€å¤§å°ã€é‡é‡

    3. æ ‡ç­¾ï¼ˆLabelsï¼‰
       - æˆ‘ä»¬æƒ³é¢„æµ‹çš„ç»“æœ
       - æ¯”å¦‚ï¼šè‹¹æœçš„å“ç§ï¼ˆçº¢å¯Œå£«ã€é»„å…ƒå¸…...ï¼‰

    4. æ¨¡å‹ï¼ˆModelï¼‰
       - AIå­¦åˆ°çš„"çŸ¥è¯†"
       - å°±åƒå­¦ç”Ÿè®°ä½çš„è§„å¾‹

    ã€æœºå™¨å­¦ä¹ çš„æ­¥éª¤ã€‘

    1. æ”¶é›†æ•°æ®
    2. å‡†å¤‡ç‰¹å¾
    3. é€‰æ‹©ç®—æ³•
    4. è®­ç»ƒæ¨¡å‹
    5. è¯„ä¼°æ•ˆæœ
    6. ä½¿ç”¨æ¨¡å‹
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬2èŠ‚ï¼šæœºå™¨å­¦ä¹ åŸºç¡€")
    print("=" * 60)
    print()

    print("ğŸ‰ è®©æˆ‘ä»¬ç”¨'æ°´æœåˆ†ç±»'æ¥ç†è§£æœºå™¨å­¦ä¹ ï¼")
    print()

    # åˆ›å»ºç®€å•çš„æ°´æœæ•°æ®
    print("ã€æ­¥éª¤1ï¼šæ”¶é›†æ•°æ®ã€‘")
    print("æˆ‘ä»¬æ”¶é›†äº†ä¸€äº›æ°´æœçš„æ•°æ®ï¼š")
    print()

    # ç‰¹å¾ï¼š[é‡é‡(å…‹), é¢œè‰²(1=çº¢è‰², 2=æ©™è‰², 3=é»„è‰²)]
    fruit_features = np.array([
        [150, 1],  # è‹¹æœ
        [160, 1],  # è‹¹æœ
        [140, 1],  # è‹¹æœ
        [200, 2],  # æ©™å­
        [180, 2],  # æ©™å­
        [190, 2],  # æ©™å­
        [120, 3],  # é¦™è•‰
        [110, 3],  # é¦™è•‰
        [130, 3],  # é¦™è•‰
    ])

    # æ ‡ç­¾ï¼š0=è‹¹æœ, 1=æ©™å­, 2=é¦™è•‰
    fruit_labels = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])
    fruit_names = ['è‹¹æœ', 'æ©™å­', 'é¦™è•‰']

    # æ˜¾ç¤ºæ•°æ®
    print("  é‡é‡(å…‹)  é¢œè‰²    æ°´æœç±»å‹")
    print("  --------  ----    --------")
    colors = {1: 'çº¢è‰²', 2: 'æ©™è‰²', 3: 'é»„è‰²'}
    for i in range(len(fruit_features)):
        weight, color = fruit_features[i]
        label = fruit_labels[i]
        print(f"    {weight:3d}     {colors[color]}      {fruit_names[label]}")

    print()
    print("ã€æ­¥éª¤2-4ï¼šè®­ç»ƒæ¨¡å‹ã€‘")
    print("æˆ‘ä»¬ä½¿ç”¨Kè¿‘é‚»ç®—æ³•ï¼ˆKNNï¼‰æ¥å­¦ä¹ è¿™äº›æ•°æ®")
    print("KNNçš„åŸç†ï¼šçœ‹æ–°æ°´æœçš„'é‚»å±…'æ˜¯ä»€ä¹ˆï¼Œå°±åˆ¤æ–­å®ƒæ˜¯ä»€ä¹ˆ")
    print()

    # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
    knn = KNeighborsClassifier(n_neighbors=3)
    knn.fit(fruit_features, fruit_labels)
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    print()
    print("ã€æ­¥éª¤5-6ï¼šä½¿ç”¨æ¨¡å‹ã€‘")
    print("ç°åœ¨è®©æˆ‘ä»¬é¢„æµ‹ä¸€äº›æ–°æ°´æœï¼š")
    print()

    # é¢„æµ‹æ–°æ•°æ®
    new_fruits = np.array([
        [155, 1],  # åº”è¯¥æ˜¯è‹¹æœ
        [185, 2],  # åº”è¯¥æ˜¯æ©™å­
        [125, 3],  # åº”è¯¥æ˜¯é¦™è•‰
    ])

    predictions = knn.predict(new_fruits)

    for i, (features, pred) in enumerate(zip(new_fruits, predictions)):
        weight, color = features
        print(f"  æ–°æ°´æœ {i+1}: {weight}å…‹, {colors[color]} â†’ é¢„æµ‹ä¸ºï¼š{fruit_names[pred]}")

    print()
    print("ğŸ’¡ æ€»ç»“ï¼š")
    print("   - ç‰¹å¾ï¼šé‡é‡ã€é¢œè‰²ï¼ˆæè¿°æ°´æœçš„å±æ€§ï¼‰")
    print("   - æ ‡ç­¾ï¼šæ°´æœç±»å‹ï¼ˆæˆ‘ä»¬è¦é¢„æµ‹çš„ï¼‰")
    print("   - æ¨¡å‹ï¼šå­¦ä¼šäº†æ ¹æ®ç‰¹å¾åˆ¤æ–­æ°´æœç±»å‹")
    print()
    input("æŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€èŠ‚...")
    print()


# ============================================
# ç¬¬3èŠ‚ï¼šsklearnå…¥é—¨
# ============================================
def lesson_3_sklearn_intro():
    """
    ç¬¬3èŠ‚ï¼šsklearn å…¥é—¨
    ====================

    å­¦ä¹ ç›®æ ‡ï¼š
    - äº†è§£sklearnåº“çš„ä½œç”¨
    - å­¦ä¼šä½¿ç”¨å†…ç½®æ•°æ®é›†
    - æŒæ¡æ•°æ®çš„åŸºæœ¬æ“ä½œ

    ã€ä»€ä¹ˆæ˜¯sklearnï¼Ÿã€‘

    sklearnï¼ˆscikit-learnï¼‰æ˜¯Pythonæœ€æµè¡Œçš„æœºå™¨å­¦ä¹ åº“
    å°±åƒä¸€ä¸ª"AIå·¥å…·ç®±"ï¼Œé‡Œé¢æœ‰å¾ˆå¤šç°æˆçš„å·¥å…·ï¼š
    - å„ç§ç®—æ³•ï¼ˆåˆ†ç±»ã€å›å½’ã€èšç±»...ï¼‰
    - ç¤ºä¾‹æ•°æ®é›†
    - æ•°æ®å¤„ç†å·¥å…·
    - æ¨¡å‹è¯„ä¼°æ–¹æ³•

    ã€sklearnå†…ç½®æ•°æ®é›†ã€‘

    sklearnæä¾›äº†ä¸€äº›ç»å…¸æ•°æ®é›†ï¼Œæ–¹ä¾¿å­¦ä¹ ï¼š
    1. irisï¼ˆé¸¢å°¾èŠ±ï¼‰ï¼šåˆ†ç±»é—®é¢˜ç»å…¸æ•°æ®
    2. bostonï¼ˆæ³¢å£«é¡¿æˆ¿ä»·ï¼‰ï¼šå›å½’é—®é¢˜æ•°æ®
    3. digitsï¼ˆæ‰‹å†™æ•°å­—ï¼‰ï¼šå›¾åƒè¯†åˆ«æ•°æ®
    4. wineï¼ˆè‘¡è„é…’ï¼‰ï¼šåˆ†ç±»æ•°æ®
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬3èŠ‚ï¼šsklearnå…¥é—¨")
    print("=" * 60)
    print()

    print("ğŸŒº è®©æˆ‘ä»¬æ¥çœ‹çœ‹sklearnçš„é¸¢å°¾èŠ±æ•°æ®é›†ï¼")
    print()

    # åŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†
    iris = datasets.load_iris()

    print("ã€æ•°æ®é›†ä»‹ç»ã€‘")
    print(f"  æ•°æ®é›†åç§°ï¼š{iris.DESCR.split('\n')[0]}")
    print(f"  æ ·æœ¬æ•°é‡ï¼š{len(iris.data)} æœµèŠ±")
    print(f"  ç‰¹å¾æ•°é‡ï¼š{iris.feature_names}")
    print(f"  ç±»åˆ«æ•°é‡ï¼š{len(iris.target_names)} ç§")
    print(f"  ç±»åˆ«åç§°ï¼š{list(iris.target_names)}")
    print()

    # è½¬æ¢ä¸ºDataFrameæ–¹ä¾¿æŸ¥çœ‹
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['target'] = iris.target
    df['target_name'] = [iris.target_names[t] for t in iris.target]

    print("ã€å‰10æ¡æ•°æ®é¢„è§ˆã€‘")
    print(df.head(10).to_string())
    print()

    print("ã€æ•°æ®ç»Ÿè®¡ã€‘")
    print(df.describe().to_string())
    print()

    # å¯è§†åŒ–
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨...")

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # å›¾1ï¼šèŠ±ç“£é•¿åº¦ vs èŠ±ç“£å®½åº¦
    colors = ['red', 'green', 'blue']
    for i, name in enumerate(iris.target_names):
        mask = df['target'] == i
        axes[0].scatter(
            df.loc[mask, 'petal length (cm)'],
            df.loc[mask, 'petal width (cm)'],
            c=colors[i],
            label=name,
            alpha=0.7
        )
    axes[0].set_xlabel('èŠ±ç“£é•¿åº¦ (cm)')
    axes[0].set_ylabel('èŠ±ç“£å®½åº¦ (cm)')
    axes[0].set_title('é¸¢å°¾èŠ±æ•°æ®é›† - èŠ±ç“£ç‰¹å¾åˆ†å¸ƒ')
    axes[0].legend()

    # å›¾2ï¼šå„ç±»åˆ«æ•°é‡
    df['target_name'].value_counts().plot(kind='bar', ax=axes[1], color=['red', 'green', 'blue'])
    axes[1].set_xlabel('å“ç§')
    axes[1].set_ylabel('æ•°é‡')
    axes[1].set_title('å„ç±»åˆ«æ ·æœ¬æ•°é‡')
    axes[1].tick_params(axis='x', rotation=0)

    plt.tight_layout()
    plt.savefig('/mnt/c/dev/python/qqstudy/ai_intro/iris_visualization.png', dpi=100)
    print("âœ… å›¾è¡¨å·²ä¿å­˜åˆ°ï¼širis_visualization.png")
    plt.close()

    print()
    print("ğŸ’¡ å°çŸ¥è¯†ï¼š")
    print("   - è¿™å°±æ˜¯æœºå™¨å­¦ä¹ ä¸­å¸¸ç”¨çš„æ•°æ®æ ¼å¼")
    print("   - æ¯è¡Œæ˜¯ä¸€ä¸ªæ ·æœ¬ï¼ˆä¸€æœµèŠ±ï¼‰")
    print("   - æ¯åˆ—æ˜¯ä¸€ä¸ªç‰¹å¾ï¼ˆèŠ±çš„å±æ€§ï¼‰")
    print()
    input("æŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€èŠ‚...")
    print()


# ============================================
# ç¬¬4èŠ‚ï¼šåˆ†ç±»é—®é¢˜ - é¸¢å°¾èŠ±
# ============================================
def lesson_4_classification():
    """
    ç¬¬4èŠ‚ï¼šåˆ†ç±»é—®é¢˜ - é¸¢å°¾èŠ±åˆ†ç±»
    =============================

    å­¦ä¹ ç›®æ ‡ï¼š
    - ç†è§£ä»€ä¹ˆæ˜¯åˆ†ç±»é—®é¢˜
    - å­¦ä¼šè®­ç»ƒåˆ†ç±»æ¨¡å‹
    - æŒæ¡æ¨¡å‹çš„ä½¿ç”¨æ–¹æ³•

    ã€ä»€ä¹ˆæ˜¯åˆ†ç±»ï¼Ÿã€‘

    åˆ†ç±» = æŠŠäº‹ç‰©åˆ†åˆ°ä¸åŒçš„ç±»åˆ«

    ä¾‹å­ï¼š
    - é‚®ä»¶ï¼šåƒåœ¾é‚®ä»¶ / æ­£å¸¸é‚®ä»¶
    - å›¾ç‰‡ï¼šçŒ« / ç‹— / é¸Ÿ
    - æ°´æœï¼šè‹¹æœ / æ©™å­ / é¦™è•‰

    ã€åˆ†ç±»çš„æ­¥éª¤ã€‘
    1. å‡†å¤‡æ•°æ®ï¼ˆå¸¦æœ‰æ ‡ç­¾çš„è®­ç»ƒæ•°æ®ï¼‰
    2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    3. é€‰æ‹©ç®—æ³•å¹¶è®­ç»ƒ
    4. é¢„æµ‹å¹¶è¯„ä¼°
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬4èŠ‚ï¼šåˆ†ç±»é—®é¢˜ - é¸¢å°¾èŠ±åˆ†ç±»")
    print("=" * 60)
    print()

    print("ğŸŒº é¸¢å°¾èŠ±åˆ†ç±»ä»»åŠ¡")
    print("ç›®æ ‡ï¼šæ ¹æ®èŠ±çš„ç‰¹å¾ï¼Œé¢„æµ‹å®ƒæ˜¯å“ªç§é¸¢å°¾èŠ±")
    print()

    # åŠ è½½æ•°æ®
    iris = datasets.load_iris()
    X = iris.data   # ç‰¹å¾ï¼ˆèŠ±è¼é•¿åº¦ã€èŠ±è¼å®½åº¦ã€èŠ±ç“£é•¿åº¦ã€èŠ±ç“£å®½åº¦ï¼‰
    y = iris.target # æ ‡ç­¾ï¼ˆèŠ±çš„å“ç§ï¼‰

    print("ã€æ­¥éª¤1ï¼šåˆ’åˆ†æ•°æ®é›†ã€‘")
    print("  è®­ç»ƒé›†ï¼šç”¨æ¥æ•™AIå­¦ä¹ ï¼ˆ70%ï¼‰")
    print("  æµ‹è¯•é›†ï¼šç”¨æ¥è€ƒè¯•ï¼Œæ£€éªŒå­¦ä¹ æ•ˆæœï¼ˆ30%ï¼‰")
    print()

    # åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    print(f"  è®­ç»ƒé›†å¤§å°ï¼š{len(X_train)} ä¸ªæ ·æœ¬")
    print(f"  æµ‹è¯•é›†å¤§å°ï¼š{len(X_test)} ä¸ªæ ·æœ¬")
    print()

    print("ã€æ­¥éª¤2ï¼šé€‰æ‹©ç®—æ³•å¹¶è®­ç»ƒã€‘")
    print("  æˆ‘ä»¬ä½¿ç”¨Kè¿‘é‚»ç®—æ³•ï¼ˆKNNï¼‰")
    print("  åŸç†ï¼šæ‰¾æœ€è¿‘çš„Kä¸ªé‚»å±…ï¼Œçœ‹å®ƒä»¬å±äºå“ªä¸€ç±»")
    print()

    # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(X_train, y_train)
    print("  âœ… è®­ç»ƒå®Œæˆï¼")

    print()
    print("ã€æ­¥éª¤3ï¼šé¢„æµ‹æµ‹è¯•é›†ã€‘")
    y_pred = knn.predict(X_test)

    # æ˜¾ç¤ºéƒ¨åˆ†é¢„æµ‹ç»“æœ
    print("  å®é™…å€¼ vs é¢„æµ‹å€¼ï¼š")
    print("  --------- ---------")
    for i in range(min(10, len(y_test))):
        actual = iris.target_names[y_test[i]]
        predicted = iris.target_names[y_pred[i]]
        match = "âœ“" if y_test[i] == y_pred[i] else "âœ—"
        print(f"  {actual:15s} {predicted:15s} {match}")

    print()
    print("ã€æ­¥éª¤4ï¼šè¯„ä¼°æ¨¡å‹ã€‘")
    accuracy = accuracy_score(y_test, y_pred)
    print(f"  å‡†ç¡®ç‡ï¼š{accuracy:.2%}")
    print(f"  ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹ç­”å¯¹äº† {int(accuracy * len(y_test))} / {len(y_test)} é¢˜")
    print()

    print("ã€æ­¥éª¤5ï¼šé¢„æµ‹æ–°æ•°æ®ã€‘")
    print("  å‡è®¾æˆ‘ä»¬åœ¨é‡å¤–å‘ç°ä¸€æœµé¸¢å°¾èŠ±ï¼š")
    print("  èŠ±è¼é•¿åº¦=5.1cm, èŠ±è¼å®½åº¦=3.5cm, èŠ±ç“£é•¿åº¦=1.4cm, èŠ±ç“£å®½åº¦=0.2cm")

    new_flower = np.array([[5.1, 3.5, 1.4, 0.2]])
    prediction = knn.predict(new_flower)
    print(f"  ğŸŒ¸ é¢„æµ‹ç»“æœï¼š{iris.target_names[prediction[0]]}")
    print()

    print("ğŸ’¡ æ€»ç»“ï¼š")
    print("   åˆ†ç±»å°±æ˜¯ç»™äº‹ç‰©è´´æ ‡ç­¾")
    print("   æ¨¡å‹é€šè¿‡å­¦ä¹ å·²çŸ¥æ ‡ç­¾çš„æ•°æ®ï¼Œæ¥é¢„æµ‹æ–°æ•°æ®çš„æ ‡ç­¾")
    print()
    input("æŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€èŠ‚...")
    print()


# ============================================
# ç¬¬5èŠ‚ï¼šå›å½’é—®é¢˜ - æˆ¿ä»·é¢„æµ‹
# ============================================
def lesson_5_regression():
    """
    ç¬¬5èŠ‚ï¼šå›å½’é—®é¢˜ - æˆ¿ä»·é¢„æµ‹
    ===========================

    å­¦ä¹ ç›®æ ‡ï¼š
    - ç†è§£ä»€ä¹ˆæ˜¯å›å½’é—®é¢˜
    - å­¦ä¼šä½¿ç”¨çº¿æ€§å›å½’
    - æŒæ¡å›å½’æ¨¡å‹çš„è¯„ä¼°

    ã€ä»€ä¹ˆæ˜¯å›å½’ï¼Ÿã€‘

    å›å½’ = é¢„æµ‹ä¸€ä¸ªè¿ç»­çš„æ•°å€¼

    ä¾‹å­ï¼š
    - æˆ¿ä»·é¢„æµ‹ï¼šæ ¹æ®é¢ç§¯ã€ä½ç½®é¢„æµ‹ä»·æ ¼
    - æ°”æ¸©é¢„æµ‹ï¼šæ ¹æ®æ—¥æœŸé¢„æµ‹æ¸©åº¦
    - è‚¡ä»·é¢„æµ‹ï¼šæ ¹æ®å†å²æ•°æ®é¢„æµ‹è‚¡ä»·

    ã€å›å½’ vs åˆ†ç±»ã€‘

    åˆ†ç±»ï¼šç»“æœæ˜¯ç±»åˆ«ï¼ˆçŒ«ã€ç‹—ã€é¸Ÿï¼‰
    å›å½’ï¼šç»“æœæ˜¯æ•°å€¼ï¼ˆ100ä¸‡ã€200ä¸‡ï¼‰

    ã€çº¿æ€§å›å½’ã€‘

    æœ€ç®€å•çš„å›å½’æ–¹æ³•
    æ‰¾ä¸€æ¡ç›´çº¿ï¼Œå°½å¯èƒ½é è¿‘æ‰€æœ‰æ•°æ®ç‚¹
    å…¬å¼ï¼šy = wx + b
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬5èŠ‚ï¼šå›å½’é—®é¢˜ - æˆ¿ä»·é¢„æµ‹")
    print("=" * 60)
    print()

    print("ğŸ  æˆ¿ä»·é¢„æµ‹ä»»åŠ¡")
    print("ç›®æ ‡ï¼šæ ¹æ®æˆ¿å±‹ç‰¹å¾ï¼Œé¢„æµ‹æˆ¿ä»·")
    print()

    # ä½¿ç”¨sklearnçš„æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®æ›¿ä»£ï¼ˆåŠ å·æˆ¿ä»·ï¼‰
    from sklearn.datasets import fetch_california_housing

    print("ã€åŠ è½½æ•°æ®ã€‘")
    california = fetch_california_housing()
    X = california.data
    y = california.target

    print(f"  æ•°æ®é›†ï¼šåŠ å·æˆ¿ä»·")
    print(f"  æ ·æœ¬æ•°é‡ï¼š{len(X)} ä¸ªæˆ¿å±‹")
    print(f"  ç‰¹å¾æ•°é‡ï¼š{X.shape[1]} ä¸ª")
    print(f"  ç‰¹å¾åç§°ï¼š{california.feature_names}")
    print()

    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(X, columns=california.feature_names)
    df['price'] = y

    print("ã€æ•°æ®é¢„è§ˆã€‘")
    print(df.head().to_string())
    print()

    # ç®€åŒ–ï¼šåªç”¨ä¸€ä¸ªç‰¹å¾ï¼ˆå¹³å‡æˆ¿é—´æ•°ï¼‰
    print("ã€ç®€åŒ–é—®é¢˜ã€‘")
    print("  ä¸ºäº†æ–¹ä¾¿ç†è§£ï¼Œæˆ‘ä»¬åªç”¨'å¹³å‡æˆ¿é—´æ•°'æ¥é¢„æµ‹æˆ¿ä»·")
    print()

    # ä½¿ç”¨å•ä¸ªç‰¹å¾
    X_rooms = X[:, [0]]  # MedIncï¼ˆæ”¶å…¥ä¸­ä½æ•°ï¼‰

    # åˆ’åˆ†æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X_rooms, y, test_size=0.3, random_state=42
    )

    print(f"  è®­ç»ƒé›†ï¼š{len(X_train)} ä¸ªæ ·æœ¬")
    print(f"  æµ‹è¯•é›†ï¼š{len(X_test)} ä¸ªæ ·æœ¬")
    print()

    print("ã€è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹ã€‘")
    model = LinearRegression()
    model.fit(X_train, y_train)
    print("  âœ… è®­ç»ƒå®Œæˆï¼")
    print()
    print(f"  å­¦åˆ°çš„ç›´çº¿æ–¹ç¨‹ï¼šæˆ¿ä»· = {model.coef_[0]:.2f} Ã— æ”¶å…¥ + {model.intercept_:.2f}")
    print()

    # é¢„æµ‹
    y_pred = model.predict(X_test)

    # è¯„ä¼°
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print("ã€æ¨¡å‹è¯„ä¼°ã€‘")
    print(f"  å‡æ–¹è¯¯å·®(MSE)ï¼š{mse:.4f}")
    print(f"  RÂ²åˆ†æ•°ï¼š{r2:.4f}")
    print(f"  RÂ²è¶Šæ¥è¿‘1ï¼Œæ¨¡å‹è¶Šå¥½")
    print()

    # å¯è§†åŒ–
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

    plt.figure(figsize=(10, 6))
    plt.scatter(X_test[:500], y_test[:500], alpha=0.5, label='å®é™…æ•°æ®', s=10)
    plt.plot(X_test[:500], y_pred[:500], 'r-', label='é¢„æµ‹ç›´çº¿', linewidth=2)
    plt.xlabel('æ”¶å…¥ä¸­ä½æ•°')
    plt.ylabel('æˆ¿ä»·ï¼ˆå•ä½ï¼š10ä¸‡ç¾å…ƒï¼‰')
    plt.title('çº¿æ€§å›å½’ï¼šæ”¶å…¥ vs æˆ¿ä»·')
    plt.legend()
    plt.savefig('/mnt/c/dev/python/qqstudy/ai_intro/regression_plot.png', dpi=100)
    print("âœ… å›¾è¡¨å·²ä¿å­˜åˆ°ï¼šregression_plot.png")
    plt.close()

    print()
    print("ã€é¢„æµ‹æ–°æ•°æ®ã€‘")
    new_income = np.array([[5.0]])  # æ”¶å…¥ä¸­ä½æ•°ä¸º5
    predicted_price = model.predict(new_income)
    print(f"  å¦‚æœæŸåœ°åŒºæ”¶å…¥ä¸­ä½æ•°ä¸º5ï¼Œé¢„æµ‹æˆ¿ä»·ä¸ºï¼š{predicted_price[0]:.2f} * 10ä¸‡ = {predicted_price[0]*10:.1f}ä¸‡ç¾å…ƒ")
    print()

    print("ğŸ’¡ æ€»ç»“ï¼š")
    print("   å›å½’ç”¨äºé¢„æµ‹è¿ç»­æ•°å€¼")
    print("   çº¿æ€§å›å½’æ‰¾ä¸€æ¡æœ€åˆé€‚çš„ç›´çº¿æ¥æ‹Ÿåˆæ•°æ®")
    print()
    input("æŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€èŠ‚...")
    print()


# ============================================
# ç¬¬6èŠ‚ï¼šæ¨¡å‹è¯„ä¼°
# ============================================
def lesson_6_evaluation():
    """
    ç¬¬6èŠ‚ï¼šæ¨¡å‹è¯„ä¼°
    =================

    å­¦ä¹ ç›®æ ‡ï¼š
    - ç†è§£æ¨¡å‹è¯„ä¼°çš„é‡è¦æ€§
    - æŒæ¡å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡
    - å­¦ä¼šåˆ¤æ–­æ¨¡å‹å¥½å

    ã€ä¸ºä»€ä¹ˆéœ€è¦è¯„ä¼°ï¼Ÿã€‘

    å°±åƒå­¦ç”Ÿéœ€è¦è€ƒè¯•ï¼Œæ¨¡å‹ä¹Ÿéœ€è¦è¯„ä¼°
    - æ£€éªŒå­¦ä¹ æ•ˆæœ
    - å‘ç°é—®é¢˜
    - æ¯”è¾ƒä¸åŒæ¨¡å‹

    ã€å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡ã€‘

    åˆ†ç±»é—®é¢˜ï¼š
    - å‡†ç¡®ç‡(Accuracy)ï¼šç­”å¯¹çš„æ¯”ä¾‹
    - ç²¾ç¡®ç‡(Precision)ï¼šé¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯çœŸ
    - å¬å›ç‡(Recall)ï¼šçœŸæ­£çš„æ­£æ ·æœ¬ï¼Œæœ‰å¤šå°‘è¢«æ‰¾åˆ°

    å›å½’é—®é¢˜ï¼š
    - å‡æ–¹è¯¯å·®(MSE)ï¼šé¢„æµ‹å€¼å’ŒçœŸå®å€¼å·®çš„å¹³æ–¹å¹³å‡
    - RÂ²åˆ†æ•°ï¼šæ¨¡å‹è§£é‡Šäº†å¤šå°‘æ•°æ®å˜åŒ–ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼‰
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬6èŠ‚ï¼šæ¨¡å‹è¯„ä¼°")
    print("=" * 60)
    print()

    print("ğŸ“Š è®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•è¯„ä¼°æ¨¡å‹çš„å¥½å")
    print()

    # åˆ†ç±»è¯„ä¼°ç¤ºä¾‹
    print("ã€åˆ†ç±»é—®é¢˜è¯„ä¼°ã€‘")
    print()

    iris = datasets.load_iris()
    X_train, X_test, y_train, y_test = train_test_split(
        iris.data, iris.target, test_size=0.3, random_state=42
    )

    # è®­ç»ƒæ¨¡å‹
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)

    # è®¡ç®—å„ç§æŒ‡æ ‡
    from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

    accuracy = accuracy_score(y_test, y_pred)

    print("  å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼š")
    print(f"    {accuracy:.2%}")
    print("    è§£é‡Šï¼šé¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹")
    print()

    print("  è¯¦ç»†åˆ†ç±»æŠ¥å‘Šï¼š")
    print(classification_report(y_test, y_pred, target_names=iris.target_names))

    # å›å½’è¯„ä¼°ç¤ºä¾‹
    print()
    print("ã€å›å½’é—®é¢˜è¯„ä¼°ã€‘")
    print()

    from sklearn.datasets import fetch_california_housing
    california = fetch_california_housing()
    X_train, X_test, y_train, y_test = train_test_split(
        california.data, california.target, test_size=0.3, random_state=42
    )

    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print(f"  å‡æ–¹è¯¯å·®(MSE)ï¼š{mse:.4f}")
    print("    è§£é‡Šï¼šé¢„æµ‹å€¼ä¸çœŸå®å€¼å·®å¼‚çš„å¹³æ–¹å¹³å‡ï¼Œè¶Šå°è¶Šå¥½")
    print()
    print(f"  å‡æ–¹æ ¹è¯¯å·®(RMSE)ï¼š{rmse:.4f}")
    print("    è§£é‡Šï¼šMSEçš„å¼€æ–¹ï¼Œå•ä½ä¸åŸæ•°æ®ç›¸åŒ")
    print()
    print(f"  RÂ²åˆ†æ•°ï¼š{r2:.4f}")
    print("    è§£é‡Šï¼šæ¨¡å‹è§£é‡Šæ•°æ®å˜åŒ–çš„æ¯”ä¾‹ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½")
    print()

    # è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ
    print("ã€é‡è¦æ¦‚å¿µï¼šè¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆã€‘")
    print()
    print("  æ¬ æ‹Ÿåˆ(Underfitting)ï¼š")
    print("    æ¨¡å‹å¤ªç®€å•ï¼Œå­¦ä¸å¤Ÿ")
    print("    å°±åƒåªèƒŒäº†å‡ ä¸ªå•è¯å°±å»è€ƒè‹±è¯­")
    print()
    print("  è¿‡æ‹Ÿåˆ(Overfitting)ï¼š")
    print("    æ¨¡å‹å¤ªå¤æ‚ï¼Œæ­»è®°ç¡¬èƒŒ")
    print("    å°±åƒæŠŠè¯¾æœ¬èƒŒä¸‹æ¥ä½†ä¸ä¼šåšé¢˜")
    print()
    print("  å¥½çš„æ¨¡å‹ï¼šåœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½è¡¨ç°è‰¯å¥½")
    print()

    print("ğŸ’¡ æ€»ç»“ï¼š")
    print("   è¯„ä¼°æ˜¯æ£€éªŒæ¨¡å‹æ•ˆæœçš„å…³é”®æ­¥éª¤")
    print("   ä¸åŒé—®é¢˜ä½¿ç”¨ä¸åŒçš„è¯„ä¼°æŒ‡æ ‡")
    print()
    input("æŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€èŠ‚...")
    print()


# ============================================
# ç¬¬7èŠ‚ï¼šæƒ…æ„Ÿåˆ†æ
# ============================================
def lesson_7_sentiment():
    """
    ç¬¬7èŠ‚ï¼šæƒ…æ„Ÿåˆ†æ - NLPå…¥é—¨
    ==========================

    å­¦ä¹ ç›®æ ‡ï¼š
    - ç†è§£è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰
    - å­¦ä¼šç®€å•çš„æ–‡æœ¬åˆ†ç±»
    - å®ç°æƒ…æ„Ÿåˆ†æ

    ã€ä»€ä¹ˆæ˜¯NLPï¼Ÿã€‘

    NLP = Natural Language Processingï¼ˆè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰
    è®©è®¡ç®—æœºç†è§£äººç±»è¯­è¨€

    åº”ç”¨ï¼š
    - æœºå™¨ç¿»è¯‘
    - æ™ºèƒ½å®¢æœ
    - æƒ…æ„Ÿåˆ†æ
    - æ–‡æœ¬åˆ†ç±»

    ã€æƒ…æ„Ÿåˆ†æã€‘

    åˆ¤æ–­ä¸€æ®µæ–‡å­—æ˜¯ç§¯æè¿˜æ˜¯æ¶ˆæ
    - æ­£é¢ï¼šå¼€å¿ƒã€æ»¡æ„ã€å–œæ¬¢...
    - è´Ÿé¢ï¼šéš¾è¿‡ã€å¤±æœ›ã€è®¨åŒ...
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬7èŠ‚ï¼šæƒ…æ„Ÿåˆ†æ - NLPå…¥é—¨")
    print("=" * 60)
    print()

    print("ğŸ˜Š è®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•åˆ†ææ–‡å­—çš„æƒ…æ„Ÿï¼")
    print()

    # ç®€å•çš„æƒ…æ„Ÿè¯å…¸æ–¹æ³•
    print("ã€æ–¹æ³•1ï¼šæƒ…æ„Ÿè¯å…¸æ³•ã€‘")
    print()

    # å®šä¹‰ç®€å•çš„æƒ…æ„Ÿè¯å…¸
    positive_words = ['å¥½', 'æ£’', 'å–œæ¬¢', 'å¼€å¿ƒ', 'é«˜å…´', 'ä¼˜ç§€', 'ç¾ä¸½', 'å¯çˆ±', 'å®Œç¾', 'èµ']
    negative_words = ['å·®', 'çƒ‚', 'è®¨åŒ', 'éš¾è¿‡', 'ä¼¤å¿ƒ', 'ç³Ÿç³•', 'ä¸‘é™‹', 'æ— èŠ', 'å¤±è´¥', 'åƒåœ¾']

    def simple_sentiment(text):
        """
        ç®€å•çš„æƒ…æ„Ÿåˆ†æå‡½æ•°

        å‚æ•°:
            text: è¦åˆ†æçš„æ–‡æœ¬ï¼ˆå­—ç¬¦ä¸²ï¼‰

        è¿”å›:
            æƒ…æ„Ÿç±»åˆ«å’Œå¾—åˆ†ï¼ˆå…ƒç»„ï¼‰

        å·¥ä½œåŸç†:
            ç»Ÿè®¡æ–‡æœ¬ä¸­æ­£é¢è¯å’Œè´Ÿé¢è¯çš„æ•°é‡
            æ ¹æ®å·®å€¼åˆ¤æ–­æƒ…æ„Ÿå€¾å‘
        """
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)

        score = positive_count - negative_count

        if score > 0:
            return 'æ­£é¢', score
        elif score < 0:
            return 'è´Ÿé¢', score
        else:
            return 'ä¸­æ€§', score

    # æµ‹è¯•
    test_texts = [
        "è¿™å®¶é¤å…çš„èœå¾ˆå¥½åƒï¼ŒæœåŠ¡ä¹Ÿå¾ˆæ£’ï¼",
        "è¿™ç”µå½±å¤ªçƒ‚äº†ï¼Œç®€ç›´æ˜¯æµªè´¹æ—¶é—´",
        "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œå¿ƒæƒ…ä¹Ÿå¾ˆå¥½",
        "è¿™äº§å“å¤ªå·®äº†ï¼Œæˆ‘å¾ˆå¤±æœ›",
        "æ™®é€šçš„ä¸€å¤©ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„"
    ]

    print("  æµ‹è¯•æƒ…æ„Ÿåˆ†æï¼š")
    for text in test_texts:
        sentiment, score = simple_sentiment(text)
        print(f"    '{text[:20]}...' â†’ {sentiment} (å¾—åˆ†: {score})")
    print()

    # æœºå™¨å­¦ä¹ æ–¹æ³•
    print("ã€æ–¹æ³•2ï¼šæœºå™¨å­¦ä¹ æ³•ã€‘")
    print()
    print("  ä½¿ç”¨sklearnè¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼š")
    print()

    from sklearn.feature_extraction.text import CountVectorizer
    from sklearn.naive_bayes import MultinomialNB

    # è®­ç»ƒæ•°æ®
    train_texts = [
        "æˆ‘å¾ˆå¼€å¿ƒ", "ä»Šå¤©çœŸé«˜å…´", "å¤ªæ£’äº†", "éå¸¸å–œæ¬¢",
        "è´¨é‡å¾ˆå¥½", "æœåŠ¡ä¼˜ç§€", "å®Œç¾ä½“éªŒ", "éå¸¸æ»¡æ„",
        "æˆ‘å¾ˆä¼¤å¿ƒ", "å¤ªè®¨åŒäº†", "çœŸç³Ÿç³•", "éå¸¸å¤±æœ›",
        "è´¨é‡å¾ˆå·®", "æœåŠ¡æ¶åŠ£", "ç³Ÿç³•ä½“éªŒ", "éå¸¸ä¸æ»¡"
    ]

    train_labels = [1, 1, 1, 1, 1, 1, 1, 1,  # æ­£é¢
                    0, 0, 0, 0, 0, 0, 0, 0]  # è´Ÿé¢

    # æ–‡æœ¬è½¬æ•°å­—ï¼ˆè¯è¢‹æ¨¡å‹ï¼‰
    vectorizer = CountVectorizer()
    X_train = vectorizer.fit_transform(train_texts)

    # è®­ç»ƒæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
    clf = MultinomialNB()
    clf.fit(X_train, train_labels)
    print("  âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print()

    # æµ‹è¯•
    test_texts = ["éå¸¸å¼€å¿ƒ", "å¤ªå·®äº†", "å¾ˆæ»¡æ„", "å¾ˆè®¨åŒ"]
    X_test = vectorizer.transform(test_texts)
    predictions = clf.predict(X_test)

    print("  é¢„æµ‹ç»“æœï¼š")
    for text, pred in zip(test_texts, predictions):
        label = "æ­£é¢" if pred == 1 else "è´Ÿé¢"
        print(f"    '{text}' â†’ {label}")
    print()

    print("ğŸ’¡ æ€»ç»“ï¼š")
    print("   NLPè®©è®¡ç®—æœºèƒ½ç†è§£äººç±»è¯­è¨€")
    print("   æƒ…æ„Ÿåˆ†æå¯ä»¥åˆ¤æ–­æ–‡å­—çš„æƒ…ç»ªå€¾å‘")
    print("   å¸¸ç”¨æ–¹æ³•ï¼šè¯å…¸æ³•ã€æœºå™¨å­¦ä¹ æ³•")
    print()
    input("æŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€èŠ‚...")
    print()


# ============================================
# ç¬¬8èŠ‚ï¼šAIçš„æœªæ¥å’Œä¼¦ç†
# ============================================
def lesson_8_future_ethics():
    """
    ç¬¬8èŠ‚ï¼šAIçš„æœªæ¥å’Œä¼¦ç†
    ======================

    å­¦ä¹ ç›®æ ‡ï¼š
    - äº†è§£AIçš„å‘å±•è¶‹åŠ¿
    - ç†è§£AIä¼¦ç†é—®é¢˜
    - åŸ¹å…»æ­£ç¡®çš„AIè§‚å¿µ

    ã€AIçš„æœªæ¥ã€‘

    1. æ›´å¼ºå¤§çš„AI
       - GPTã€å¤§è¯­è¨€æ¨¡å‹
       - å¤šæ¨¡æ€AIï¼ˆæ–‡å­—ã€å›¾åƒã€å£°éŸ³ï¼‰

    2. AIæ— å¤„ä¸åœ¨
       - è‡ªåŠ¨é©¾é©¶
       - æ™ºèƒ½å®¶å±…
       - åŒ»ç–—è¯Šæ–­

    3. AIåˆ›é€ 
       - AIç»˜ç”»
       - AIä½œæ›²
       - AIå†™ä½œ

    ã€AIä¼¦ç†ã€‘

    1. å…¬å¹³æ€§
       - AIä¼šæœ‰åè§å—ï¼Ÿ
       - å¦‚ä½•ç¡®ä¿å…¬å¹³ï¼Ÿ

    2. éšç§
       - AIéœ€è¦æ•°æ®ï¼Œä½†æ•°æ®ä»å“ªæ¥ï¼Ÿ
       - æˆ‘ä»¬çš„æ•°æ®å®‰å…¨å—ï¼Ÿ

    3. å°±ä¸š
       - AIä¼šå–ä»£äººç±»å·¥ä½œå—ï¼Ÿ
       - æˆ‘ä»¬åº”è¯¥å­¦ä¹ ä»€ä¹ˆï¼Ÿ

    4. è´£ä»»
       - AIçŠ¯é”™ï¼Œè°æ¥è´Ÿè´£ï¼Ÿ
       - å¦‚ä½•ç›‘ç®¡AIï¼Ÿ
    """
    print("=" * 60)
    print("ğŸ“š ç¬¬8èŠ‚ï¼šAIçš„æœªæ¥å’Œä¼¦ç†")
    print("=" * 60)
    print()

    print("ğŸ”® è®©æˆ‘ä»¬æ¥æ€è€ƒAIçš„æœªæ¥å’Œä¼¦ç†é—®é¢˜")
    print()

    print("ã€AIçš„æœªæ¥å‘å±•è¶‹åŠ¿ã€‘")
    print()
    print("  1. å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰")
    print("     - åƒGPTè¿™æ ·çš„AIèƒ½ç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€")
    print("     - å¯ä»¥å¯¹è¯ã€å†™ä½œã€ç¼–ç¨‹...")
    print()
    print("  2. å¤šæ¨¡æ€AI")
    print("     - èƒ½åŒæ—¶ç†è§£æ–‡å­—ã€å›¾ç‰‡ã€å£°éŸ³ã€è§†é¢‘")
    print("     - åƒäººç±»ä¸€æ ·ï¼Œç”¨å¤šç§æ–¹å¼æ„ŸçŸ¥ä¸–ç•Œ")
    print()
    print("  3. é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰")
    print("     - åƒäººç±»ä¸€æ ·æ€è€ƒå’Œå­¦ä¹ çš„AI")
    print("     - ç›®å‰è¿˜åœ¨ç ”ç©¶ä¸­")
    print()

    print("ã€AIä¼¦ç†é—®é¢˜æ€è€ƒã€‘")
    print()

    # äº’åŠ¨æ€è€ƒé—®é¢˜
    questions = [
        {
            "q": "å¦‚æœAIèƒ½å¸®ä½ å†™ä½œä¸šï¼Œä½ è¿˜ä¼šè‡ªå·±å­¦å—ï¼Ÿ",
            "thought": "å­¦ä¹ ä¸åªæ˜¯ä¸ºäº†ç­”æ¡ˆï¼Œæ›´æ˜¯ä¸ºäº†åŸ¹å…»æ€ç»´èƒ½åŠ›"
        },
        {
            "q": "AIç”¨äººè„¸è¯†åˆ«æŠ“åäººï¼Œä½†ä¹Ÿå¯èƒ½ç›‘è§†æ™®é€šäººï¼Œè¿™å¥½å—ï¼Ÿ",
            "thought": "å®‰å…¨ä¸éšç§ä¹‹é—´éœ€è¦å¹³è¡¡"
        },
        {
            "q": "è‡ªåŠ¨é©¾é©¶æ±½è½¦å‡ºäº†äº‹æ•…ï¼Œåº”è¯¥ç”±è°è´Ÿè´£ï¼Ÿ",
            "thought": "AIçš„è´£ä»»å½’å±æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜"
        },
        {
            "q": "AIå¯ä»¥åˆ›ä½œè‰ºæœ¯å“ï¼Œè¿™ç®—è‰ºæœ¯å—ï¼Ÿ",
            "thought": "è‰ºæœ¯çš„å®šä¹‰å¯èƒ½éœ€è¦é‡æ–°æ€è€ƒ"
        }
    ]

    for i, item in enumerate(questions, 1):
        print(f"  æ€è€ƒ{i}ï¼š{item['q']}")
        print(f"    â†’ {item['thought']}")
        print()

    print("ã€å¦‚ä½•æ­£ç¡®çœ‹å¾…AIã€‘")
    print()
    print("  âœ… AIæ˜¯å·¥å…·ï¼Œä¸æ˜¯ç¥")
    print("  âœ… AIå¯ä»¥å¸®åŠ©äººç±»ï¼Œä½†ä¸èƒ½å®Œå…¨æ›¿ä»£äººç±»")
    print("  âœ… å­¦ä¹ AIçŸ¥è¯†ï¼Œæ›´å¥½åœ°ä½¿ç”¨AI")
    print("  âœ… ä¿æŒæ€è€ƒï¼Œä¸è¦ç›²ç›®ç›¸ä¿¡AI")
    print("  âœ… å…³æ³¨ä¼¦ç†ï¼Œè´Ÿè´£ä»»åœ°å‘å±•AI")
    print()

    print("ã€å­¦ä¹ å»ºè®®ã€‘")
    print()
    print("  1. æ‰“å¥½æ•°å­¦åŸºç¡€ï¼ˆä»£æ•°ã€æ¦‚ç‡ã€ç»Ÿè®¡ï¼‰")
    print("  2. å­¦å¥½ç¼–ç¨‹ï¼ˆPythonæ˜¯AIä¸»æµè¯­è¨€ï¼‰")
    print("  3. å¤šåŠ¨æ‰‹å®è·µï¼Œåšé¡¹ç›®")
    print("  4. å…³æ³¨AIæ–°é—»å’Œå‘å±•")
    print("  5. åŸ¹å…»æ‰¹åˆ¤æ€§æ€ç»´")
    print()

    print("=" * 60)
    print("ğŸ‰ æ­å–œä½ å®Œæˆäº†AIå…¥é—¨é€Ÿæˆæ•™ç¨‹ï¼")
    print("=" * 60)
    print()
    print("  ä½ å·²ç»å­¦ä¼šäº†ï¼š")
    print("  âœ“ ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½")
    print("  âœ“ æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ")
    print("  âœ“ ä½¿ç”¨sklearnè¿›è¡Œåˆ†ç±»å’Œå›å½’")
    print("  âœ“ æ¨¡å‹è¯„ä¼°æ–¹æ³•")
    print("  âœ“ ç®€å•çš„æƒ…æ„Ÿåˆ†æ")
    print("  âœ“ AIä¼¦ç†æ€è€ƒ")
    print()
    print("  æ¥ä¸‹æ¥å¯ä»¥ï¼š")
    print("  1. å®Œæˆ ai_exercises.py ä¸­çš„ç»ƒä¹ é¢˜")
    print("  2. è¿è¡Œ projects/ æ–‡ä»¶å¤¹ä¸­çš„é¡¹ç›®")
    print("  3. ç»§ç»­æ·±å…¥å­¦ä¹ æœºå™¨å­¦ä¹ ç®—æ³•")
    print()
    print("  åŠ æ²¹ï¼Œæœªæ¥çš„AIå·¥ç¨‹å¸ˆï¼ğŸš€")
    print()


# ============================================
# ä¸»ç¨‹åº
# ============================================
def main():
    """
    ä¸»ç¨‹åºå…¥å£

    è¿è¡Œæ‰€æœ‰æ•™ç¨‹ç« èŠ‚
    """
    print("\n" + "ğŸ¯ AIå…¥é—¨é€Ÿæˆæ•™ç¨‹ - å¼€å§‹å­¦ä¹ ï¼" + "\n")

    # è¿è¡Œæ‰€æœ‰ç« èŠ‚
    lesson_1_what_is_ai()
    lesson_2_ml_basics()
    lesson_3_sklearn_intro()
    lesson_4_classification()
    lesson_5_regression()
    lesson_6_evaluation()
    lesson_7_sentiment()
    lesson_8_future_ethics()


if __name__ == "__main__":
    main()
