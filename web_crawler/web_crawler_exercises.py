# -*- coding: utf-8 -*-
"""
ç½‘ç»œçˆ¬è™«ç»ƒä¹ é¢˜ - å¸¦ç­”æ¡ˆ
========================

ä½¿ç”¨è¯´æ˜ï¼š
1. æ¯é“ç»ƒä¹ é¢˜éƒ½æœ‰ä¸€ä¸ªç»ƒä¹ å‡½æ•°å’Œä¸€ä¸ªç­”æ¡ˆå‡½æ•°
2. å»ºè®®å…ˆè‡ªå·±å®Œæˆç»ƒä¹ å‡½æ•°ä¸­çš„ TODO éƒ¨åˆ†
3. å®Œæˆåå¯ä»¥æŸ¥çœ‹ç­”æ¡ˆå‡½æ•°éªŒè¯

è¿è¡Œæ–¹æ³•ï¼š
python web_crawler_exercises.py
"""

print("=" * 60)
print("ğŸ“ ç½‘ç»œçˆ¬è™«ç»ƒä¹ é¢˜")
print("=" * 60)


# ============================================================
# ç»ƒä¹ 1ï¼šå‘é€HTTPè¯·æ±‚
# ============================================================
"""
ç»ƒä¹ 1ï¼šå‘é€HTTPè¯·æ±‚

ç›®æ ‡ï¼šå­¦ä¼šä½¿ç”¨ requests åº“å‘é€HTTPè¯·æ±‚

ä»»åŠ¡ï¼š
1. å‘é€GETè¯·æ±‚åˆ° https://httpbin.org/get
2. æ‰“å°çŠ¶æ€ç 
3. æ‰“å°å“åº”å†…å®¹çš„å‰100ä¸ªå­—ç¬¦
"""

def exercise_1_request():
    """
    ç»ƒä¹ 1ï¼šå‘é€HTTPè¯·æ±‚

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    import requests

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 1ï¼šå‘é€HTTPè¯·æ±‚")
    print("=" * 40)

    # TODO: è®¾ç½®URL
    url = "https://httpbin.org/get"

    # TODO: å‘é€GETè¯·æ±‚
    response = requests.get(url)

    # TODO: æ‰“å°çŠ¶æ€ç 
    print(f"çŠ¶æ€ç : {response.status_code}")

    # TODO: æ‰“å°å“åº”å†…å®¹çš„å‰100ä¸ªå­—ç¬¦
    print(f"å“åº”å†…å®¹: {response.text[:100]}...")


def answer_1_request():
    """
    ç»ƒä¹ 1ç­”æ¡ˆ
    """
    import requests

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 1ç­”æ¡ˆ")
    print("=" * 40)

    # è®¾ç½®URL
    url = "https://httpbin.org/get"

    # å‘é€GETè¯·æ±‚
    response = requests.get(url)

    # æ‰“å°çŠ¶æ€ç 
    print(f"çŠ¶æ€ç : {response.status_code}")

    # æ‰“å°å“åº”å†…å®¹çš„å‰100ä¸ªå­—ç¬¦
    print(f"å“åº”å†…å®¹: {response.text[:100]}...")

    print("\nâœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. ä½¿ç”¨ requests.get(url) å‘é€GETè¯·æ±‚")
    print("2. response.status_code è·å–çŠ¶æ€ç ï¼ˆ200è¡¨ç¤ºæˆåŠŸï¼‰")
    print("3. response.text è·å–å“åº”å†…å®¹ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰")


# ============================================================
# ç»ƒä¹ 2ï¼šå¸¦å‚æ•°çš„è¯·æ±‚
# ============================================================
"""
ç»ƒä¹ 2ï¼šå¸¦å‚æ•°çš„è¯·æ±‚

ç›®æ ‡ï¼šå­¦ä¼šåœ¨è¯·æ±‚ä¸­ä¼ é€’å‚æ•°

ä»»åŠ¡ï¼š
1. å‘é€å¸¦å‚æ•°çš„GETè¯·æ±‚
2. å‚æ•°ï¼šsearch="python", page=1
3. æ‰“å°å®é™…è¯·æ±‚çš„URL
"""

def exercise_2_params():
    """
    ç»ƒä¹ 2ï¼šå¸¦å‚æ•°çš„è¯·æ±‚

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    import requests

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 2ï¼šå¸¦å‚æ•°çš„è¯·æ±‚")
    print("=" * 40)

    # TODO: è®¾ç½®URLå’Œå‚æ•°
    url = "https://httpbin.org/get"
    params = {"search": "python", "page": 1}

    # TODO: å‘é€å¸¦å‚æ•°çš„è¯·æ±‚
    response = requests.get(url, params=params)

    # TODO: æ‰“å°å®é™…è¯·æ±‚çš„URL
    print(f"å®é™…è¯·æ±‚URL: {response.url}")


def answer_2_params():
    """
    ç»ƒä¹ 2ç­”æ¡ˆ
    """
    import requests

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 2ç­”æ¡ˆ")
    print("=" * 40)

    url = "https://httpbin.org/get"
    params = {"search": "python", "page": 1}

    # å‘é€å¸¦å‚æ•°çš„è¯·æ±‚
    response = requests.get(url, params=params)

    # æ‰“å°å®é™…è¯·æ±‚çš„URL
    print(f"å®é™…è¯·æ±‚URL: {response.url}")

    print("\nâœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. ä½¿ç”¨ params å‚æ•°ä¼ é€’URLå‚æ•°")
    print("2. requests ä¼šè‡ªåŠ¨å°†å‚æ•°æ‹¼æ¥åˆ°URLä¸­")
    print("3. response.url å¯ä»¥æŸ¥çœ‹å®é™…è¯·æ±‚çš„å®Œæ•´URL")


# ============================================================
# ç»ƒä¹ 3ï¼šè§£æHTML
# ============================================================
"""
ç»ƒä¹ 3ï¼šè§£æHTML

ç›®æ ‡ï¼šå­¦ä¼šä½¿ç”¨ BeautifulSoup è§£æHTML

ä»»åŠ¡ï¼š
ç»™å®šHTMLä»£ç ï¼Œæå–ï¼š
1. ç½‘é¡µæ ‡é¢˜
2. æ‰€æœ‰æ®µè½å†…å®¹
3. ç¬¬ä¸€ä¸ªé“¾æ¥çš„åœ°å€
"""

def exercise_3_parse():
    """
    ç»ƒä¹ 3ï¼šè§£æHTML

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    from bs4 import BeautifulSoup

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 3ï¼šè§£æHTML")
    print("=" * 40)

    html = """
    <html>
        <head><title>æˆ‘çš„ç½‘é¡µ</title></head>
        <body>
            <h1>æ¬¢è¿</h1>
            <p>è¿™æ˜¯ç¬¬ä¸€æ®µã€‚</p>
            <p>è¿™æ˜¯ç¬¬äºŒæ®µã€‚</p>
            <a href="https://example.com">ç¤ºä¾‹é“¾æ¥</a>
            <a href="https://python.org">Pythonå®˜ç½‘</a>
        </body>
    </html>
    """

    # TODO: åˆ›å»ºBeautifulSoupå¯¹è±¡
    soup = BeautifulSoup(html, 'html.parser')

    # TODO: æå–å¹¶æ‰“å°ç½‘é¡µæ ‡é¢˜
    title = soup.title.text
    print(f"ç½‘é¡µæ ‡é¢˜: {title}")

    # TODO: æå–å¹¶æ‰“å°æ‰€æœ‰æ®µè½
    paragraphs = soup.find_all('p')
    print(f"æ®µè½å†…å®¹:")
    for p in paragraphs:
        print(f"  - {p.text}")

    # TODO: æå–å¹¶æ‰“å°ç¬¬ä¸€ä¸ªé“¾æ¥çš„åœ°å€
    first_link = soup.find('a')
    print(f"ç¬¬ä¸€ä¸ªé“¾æ¥åœ°å€: {first_link['href']}")


def answer_3_parse():
    """
    ç»ƒä¹ 3ç­”æ¡ˆ
    """
    from bs4 import BeautifulSoup

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 3ç­”æ¡ˆ")
    print("=" * 40)

    html = """
    <html>
        <head><title>æˆ‘çš„ç½‘é¡µ</title></head>
        <body>
            <h1>æ¬¢è¿</h1>
            <p>è¿™æ˜¯ç¬¬ä¸€æ®µã€‚</p>
            <p>è¿™æ˜¯ç¬¬äºŒæ®µã€‚</p>
            <a href="https://example.com">ç¤ºä¾‹é“¾æ¥</a>
            <a href="https://python.org">Pythonå®˜ç½‘</a>
        </body>
    </html>
    """

    soup = BeautifulSoup(html, 'html.parser')

    # æå–ç½‘é¡µæ ‡é¢˜
    title = soup.title.text
    print(f"ç½‘é¡µæ ‡é¢˜: {title}")

    # æå–æ‰€æœ‰æ®µè½
    paragraphs = soup.find_all('p')
    print(f"æ®µè½å†…å®¹:")
    for p in paragraphs:
        print(f"  - {p.text}")

    # æå–ç¬¬ä¸€ä¸ªé“¾æ¥çš„åœ°å€
    first_link = soup.find('a')
    print(f"ç¬¬ä¸€ä¸ªé“¾æ¥åœ°å€: {first_link['href']}")

    print("\nâœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. BeautifulSoup(html, 'html.parser') åˆ›å»ºè§£æå¯¹è±¡")
    print("2. soup.title.text è·å–æ ‡é¢˜æ–‡æœ¬")
    print("3. soup.find_all('p') è·å–æ‰€æœ‰<p>æ ‡ç­¾")
    print("4. soup.find('a') è·å–ç¬¬ä¸€ä¸ª<a>æ ‡ç­¾")
    print("5. element['attr'] è·å–å±æ€§å€¼")


# ============================================================
# ç»ƒä¹ 4ï¼šCSSé€‰æ‹©å™¨
# ============================================================
"""
ç»ƒä¹ 4ï¼šCSSé€‰æ‹©å™¨

ç›®æ ‡ï¼šå­¦ä¼šä½¿ç”¨CSSé€‰æ‹©å™¨æå–æ•°æ®

ä»»åŠ¡ï¼š
ç»™å®šHTMLä»£ç ï¼Œä½¿ç”¨CSSé€‰æ‹©å™¨æå–ï¼š
1. classä¸º"highlight"çš„å…ƒç´ å†…å®¹
2. idä¸º"main"çš„å…ƒç´ å†…çš„æ‰€æœ‰åˆ—è¡¨é¡¹
3. æ‰€æœ‰é“¾æ¥çš„hrefå±æ€§
"""

def exercise_4_selector():
    """
    ç»ƒä¹ 4ï¼šCSSé€‰æ‹©å™¨

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    from bs4 import BeautifulSoup

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 4ï¼šCSSé€‰æ‹©å™¨")
    print("=" * 40)

    html = """
    <div id="main">
        <h1 class="highlight">é‡è¦æ ‡é¢˜</h1>
        <p class="highlight">é‡è¦å†…å®¹</p>
        <ul>
            <li>é¡¹ç›®1</li>
            <li>é¡¹ç›®2</li>
            <li>é¡¹ç›®3</li>
        </ul>
        <nav>
            <a href="/home">é¦–é¡µ</a>
            <a href="/about">å…³äº</a>
        </nav>
    </div>
    """

    # TODO: åˆ›å»ºBeautifulSoupå¯¹è±¡
    soup = BeautifulSoup(html, 'html.parser')

    # TODO: ä½¿ç”¨CSSé€‰æ‹©å™¨æå–classä¸º"highlight"çš„å…ƒç´ 
    highlights = soup.select('.highlight')
    print("classä¸ºhighlightçš„å…ƒç´ :")
    for el in highlights:
        print(f"  - {el.text}")

    # TODO: ä½¿ç”¨CSSé€‰æ‹©å™¨æå–idä¸º"main"å†…çš„æ‰€æœ‰li
    items = soup.select('#main li')
    print("\nidä¸ºmainå†…çš„åˆ—è¡¨é¡¹:")
    for item in items:
        print(f"  - {item.text}")

    # TODO: ä½¿ç”¨CSSé€‰æ‹©å™¨æå–æ‰€æœ‰é“¾æ¥çš„href
    links = soup.select('a')
    print("\næ‰€æœ‰é“¾æ¥:")
    for link in links:
        print(f"  - {link.text}: {link['href']}")


def answer_4_selector():
    """
    ç»ƒä¹ 4ç­”æ¡ˆ
    """
    from bs4 import BeautifulSoup

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 4ç­”æ¡ˆ")
    print("=" * 40)

    html = """
    <div id="main">
        <h1 class="highlight">é‡è¦æ ‡é¢˜</h1>
        <p class="highlight">é‡è¦å†…å®¹</p>
        <ul>
            <li>é¡¹ç›®1</li>
            <li>é¡¹ç›®2</li>
            <li>é¡¹ç›®3</li>
        </ul>
        <nav>
            <a href="/home">é¦–é¡µ</a>
            <a href="/about">å…³äº</a>
        </nav>
    </div>
    """

    soup = BeautifulSoup(html, 'html.parser')

    # ä½¿ç”¨CSSé€‰æ‹©å™¨æå–classä¸º"highlight"çš„å…ƒç´ 
    highlights = soup.select('.highlight')
    print("classä¸ºhighlightçš„å…ƒç´ :")
    for el in highlights:
        print(f"  - {el.text}")

    # ä½¿ç”¨CSSé€‰æ‹©å™¨æå–idä¸º"main"å†…çš„æ‰€æœ‰li
    items = soup.select('#main li')
    print("\nidä¸ºmainå†…çš„åˆ—è¡¨é¡¹:")
    for item in items:
        print(f"  - {item.text}")

    # ä½¿ç”¨CSSé€‰æ‹©å™¨æå–æ‰€æœ‰é“¾æ¥çš„href
    links = soup.select('a')
    print("\næ‰€æœ‰é“¾æ¥:")
    for link in links:
        print(f"  - {link.text}: {link['href']}")

    print("\nâœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. soup.select('.class') - æŒ‰classé€‰æ‹©")
    print("2. soup.select('#id') - æŒ‰idé€‰æ‹©")
    print("3. soup.select('#id li') - é€‰æ‹©idå†…æ‰€æœ‰li")
    print("4. CSSé€‰æ‹©å™¨æ›´çµæ´»ï¼Œæ”¯æŒç»„åˆé€‰æ‹©")


# ============================================================
# ç»ƒä¹ 5ï¼šä¿å­˜æ•°æ®åˆ°CSV
# ============================================================
"""
ç»ƒä¹ 5ï¼šä¿å­˜æ•°æ®åˆ°CSV

ç›®æ ‡ï¼šå­¦ä¼šå°†æ•°æ®ä¿å­˜ä¸ºCSVæ–‡ä»¶

ä»»åŠ¡ï¼š
å°†ä»¥ä¸‹å­¦ç”Ÿæ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶ï¼š
- è¡¨å¤´ï¼šå§“å, å¹´é¾„, ç­çº§
- æ•°æ®ï¼šå¼ ä¸‰, 14, åˆäºŒ1ç­
        æå››, 15, åˆäºŒ2ç­
        ç‹äº”, 14, åˆäºŒ1ç­
"""

def exercise_5_csv():
    """
    ç»ƒä¹ 5ï¼šä¿å­˜æ•°æ®åˆ°CSV

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    import csv
    import os

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 5ï¼šä¿å­˜æ•°æ®åˆ°CSV")
    print("=" * 40)

    # æ•°æ®
    students = [
        {"name": "å¼ ä¸‰", "age": 14, "class": "åˆäºŒ1ç­"},
        {"name": "æå››", "age": 15, "class": "åˆäºŒ2ç­"},
        {"name": "ç‹äº”", "age": 14, "class": "åˆäºŒ1ç­"},
    ]

    # ä¿å­˜è·¯å¾„
    save_dir = "/mnt/c/dev/python/qqstudy/web_crawler/data"
    os.makedirs(save_dir, exist_ok=True)
    filepath = os.path.join(save_dir, "students.csv")

    # TODO: å°†æ•°æ®å†™å…¥CSVæ–‡ä»¶
    with open(filepath, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['name', 'age', 'class'])
        writer.writeheader()
        writer.writerows(students)

    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")


def answer_5_csv():
    """
    ç»ƒä¹ 5ç­”æ¡ˆ
    """
    import csv
    import os

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 5ç­”æ¡ˆ")
    print("=" * 40)

    students = [
        {"name": "å¼ ä¸‰", "age": 14, "class": "åˆäºŒ1ç­"},
        {"name": "æå››", "age": 15, "class": "åˆäºŒ2ç­"},
        {"name": "ç‹äº”", "age": 14, "class": "åˆäºŒ1ç­"},
    ]

    save_dir = "/mnt/c/dev/python/qqstudy/web_crawler/data"
    os.makedirs(save_dir, exist_ok=True)
    filepath = os.path.join(save_dir, "students_answer.csv")

    with open(filepath, 'w', newline='', encoding='utf-8') as f:
        # åˆ›å»ºå­—å…¸å†™å…¥å™¨
        writer = csv.DictWriter(f, fieldnames=['name', 'age', 'class'])

        # å†™å…¥è¡¨å¤´
        writer.writeheader()

        # å†™å…¥æ•°æ®
        writer.writerows(students)

    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")

    # è¯»å–å¹¶æ˜¾ç¤ºå†…å®¹
    with open(filepath, 'r', encoding='utf-8') as f:
        print("\næ–‡ä»¶å†…å®¹:")
        print(f.read())

    print("âœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. csv.DictWriter å¯ä»¥ç›´æ¥å†™å…¥å­—å…¸åˆ—è¡¨")
    print("2. fieldnames æŒ‡å®šå­—æ®µé¡ºåº")
    print("3. writeheader() å†™å…¥è¡¨å¤´")
    print("4. writerows() å†™å…¥å¤šè¡Œæ•°æ®")


# ============================================================
# ç»ƒä¹ 6ï¼šä¿å­˜æ•°æ®åˆ°JSON
# ============================================================
"""
ç»ƒä¹ 6ï¼šä¿å­˜æ•°æ®åˆ°JSON

ç›®æ ‡ï¼šå­¦ä¼šå°†æ•°æ®ä¿å­˜ä¸ºJSONæ–‡ä»¶

ä»»åŠ¡ï¼š
å°†ä¹¦ç±æ•°æ®ä¿å­˜åˆ°JSONæ–‡ä»¶ï¼Œè¦æ±‚ï¼š
1. æ ¼å¼åŒ–è¾“å‡ºï¼ˆç¼©è¿›4ç©ºæ ¼ï¼‰
2. ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º
"""

def exercise_6_json():
    """
    ç»ƒä¹ 6ï¼šä¿å­˜æ•°æ®åˆ°JSON

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    import json
    import os

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 6ï¼šä¿å­˜æ•°æ®åˆ°JSON")
    print("=" * 40)

    # æ•°æ®
    books = {
        "category": "ç¼–ç¨‹",
        "books": [
            {"title": "Pythonå…¥é—¨", "price": 59},
            {"title": "çˆ¬è™«å®æˆ˜", "price": 79},
        ]
    }

    # ä¿å­˜è·¯å¾„
    save_dir = "/mnt/c/dev/python/qqstudy/web_crawler/data"
    os.makedirs(save_dir, exist_ok=True)
    filepath = os.path.join(save_dir, "books.json")

    # TODO: å°†æ•°æ®å†™å…¥JSONæ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(books, f, ensure_ascii=False, indent=4)

    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")


def answer_6_json():
    """
    ç»ƒä¹ 6ç­”æ¡ˆ
    """
    import json
    import os

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 6ç­”æ¡ˆ")
    print("=" * 40)

    books = {
        "category": "ç¼–ç¨‹",
        "books": [
            {"title": "Pythonå…¥é—¨", "price": 59},
            {"title": "çˆ¬è™«å®æˆ˜", "price": 79},
        ]
    }

    save_dir = "/mnt/c/dev/python/qqstudy/web_crawler/data"
    os.makedirs(save_dir, exist_ok=True)
    filepath = os.path.join(save_dir, "books_answer.json")

    # å†™å…¥JSONæ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        # ensure_ascii=False ä¿è¯ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º
        # indent=4 æ ¼å¼åŒ–è¾“å‡º
        json.dump(books, f, ensure_ascii=False, indent=4)

    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")

    # è¯»å–å¹¶æ˜¾ç¤ºå†…å®¹
    with open(filepath, 'r', encoding='utf-8') as f:
        print("\næ–‡ä»¶å†…å®¹:")
        print(f.read())

    print("\nâœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. json.dump(data, file) å°†æ•°æ®å†™å…¥JSONæ–‡ä»¶")
    print("2. ensure_ascii=False ä¿è¯ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º")
    print("3. indent=4 æ ¼å¼åŒ–è¾“å‡ºï¼Œä¾¿äºé˜…è¯»")


# ============================================================
# ç»ƒä¹ 7ï¼šå®Œæ•´çˆ¬è™«
# ============================================================
"""
ç»ƒä¹ 7ï¼šå®Œæ•´çˆ¬è™«

ç›®æ ‡ï¼šç»¼åˆè¿ç”¨æ‰€å­¦çŸ¥è¯†å®Œæˆä¸€ä¸ªç®€å•çˆ¬è™«

ä»»åŠ¡ï¼š
çˆ¬å–æ¨¡æ‹Ÿçš„HTMLé¡µé¢ï¼Œæå–å•†å“ä¿¡æ¯å¹¶ä¿å­˜
"""

def exercise_7_complete():
    """
    ç»ƒä¹ 7ï¼šå®Œæ•´çˆ¬è™«

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    from bs4 import BeautifulSoup
    import json
    import os

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 7ï¼šå®Œæ•´çˆ¬è™«")
    print("=" * 40)

    # æ¨¡æ‹Ÿçš„ç½‘é¡µHTML
    html = """
    <div class="products">
        <div class="product">
            <h2 class="title">Pythonç¼–ç¨‹ä¹¦</h2>
            <span class="price">59.00</span>
            <p class="desc">é€‚åˆåˆå­¦è€…</p>
        </div>
        <div class="product">
            <h2 class="title">æ•°æ®ç»“æ„</h2>
            <span class="price">49.00</span>
            <p class="desc">è®¡ç®—æœºåŸºç¡€</p>
        </div>
        <div class="product">
            <h2 class="title">ç½‘ç»œçˆ¬è™«å®æˆ˜</h2>
            <span class="price">69.00</span>
            <p class="desc">è¿›é˜¶æ•™ç¨‹</p>
        </div>
    </div>
    """

    # TODO: 1. åˆ›å»ºBeautifulSoupå¯¹è±¡
    soup = BeautifulSoup(html, 'html.parser')

    # TODO: 2. æ‰¾åˆ°æ‰€æœ‰å•†å“
    products = soup.find_all('div', class_='product')

    # TODO: 3. æå–æ¯ä¸ªå•†å“çš„ä¿¡æ¯
    all_products = []
    for product in products:
        title = product.find('h2', class_='title').text
        price = product.find('span', class_='price').text
        desc = product.find('p', class_='desc').text

        product_data = {
            'title': title,
            'price': price,
            'desc': desc
        }
        all_products.append(product_data)

        print(f"æå–: {title} - {price}å…ƒ")

    # TODO: 4. ä¿å­˜åˆ°JSONæ–‡ä»¶
    save_dir = "/mnt/c/dev/python/qqstudy/web_crawler/data"
    os.makedirs(save_dir, exist_ok=True)
    filepath = os.path.join(save_dir, "products.json")

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(all_products, f, ensure_ascii=False, indent=4)

    print(f"\nâœ… å…±æå– {len(all_products)} ä¸ªå•†å“")
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")


def answer_7_complete():
    """
    ç»ƒä¹ 7ç­”æ¡ˆ
    """
    from bs4 import BeautifulSoup
    import json
    import os

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 7ç­”æ¡ˆ")
    print("=" * 40)

    html = """
    <div class="products">
        <div class="product">
            <h2 class="title">Pythonç¼–ç¨‹ä¹¦</h2>
            <span class="price">59.00</span>
            <p class="desc">é€‚åˆåˆå­¦è€…</p>
        </div>
        <div class="product">
            <h2 class="title">æ•°æ®ç»“æ„</h2>
            <span class="price">49.00</span>
            <p class="desc">è®¡ç®—æœºåŸºç¡€</p>
        </div>
        <div class="product">
            <h2 class="title">ç½‘ç»œçˆ¬è™«å®æˆ˜</h2>
            <span class="price">69.00</span>
            <p class="desc">è¿›é˜¶æ•™ç¨‹</p>
        </div>
    </div>
    """

    # 1. åˆ›å»ºBeautifulSoupå¯¹è±¡
    soup = BeautifulSoup(html, 'html.parser')

    # 2. æ‰¾åˆ°æ‰€æœ‰å•†å“
    products = soup.find_all('div', class_='product')

    # 3. æå–æ¯ä¸ªå•†å“çš„ä¿¡æ¯
    all_products = []
    for product in products:
        # æå–æ ‡é¢˜
        title = product.find('h2', class_='title').text
        # æå–ä»·æ ¼
        price = product.find('span', class_='price').text
        # æå–æè¿°
        desc = product.find('p', class_='desc').text

        product_data = {
            'title': title,
            'price': price,
            'desc': desc
        }
        all_products.append(product_data)

        print(f"æå–: {title} - {price}å…ƒ")

    # 4. ä¿å­˜åˆ°JSONæ–‡ä»¶
    save_dir = "/mnt/c/dev/python/qqstudy/web_crawler/data"
    os.makedirs(save_dir, exist_ok=True)
    filepath = os.path.join(save_dir, "products_answer.json")

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(all_products, f, ensure_ascii=False, indent=4)

    print(f"\nâœ… å…±æå– {len(all_products)} ä¸ªå•†å“")
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")

    print("\nâœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. åˆ›å»ºBeautifulSoupå¯¹è±¡è§£æHTML")
    print("2. find_all() æ‰¾åˆ°æ‰€æœ‰å•†å“å®¹å™¨")
    print("3. å¾ªç¯æ¯ä¸ªå•†å“ï¼Œç”¨find()æå–å…·ä½“ä¿¡æ¯")
    print("4. json.dump() ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶")


# ============================================================
# ç»ƒä¹ 8ï¼šç¿»é¡µçˆ¬å–ï¼ˆæ¨¡æ‹Ÿï¼‰
# ============================================================
"""
ç»ƒä¹ 8ï¼šç¿»é¡µçˆ¬å–

ç›®æ ‡ï¼šå­¦ä¼šå¤„ç†å¤šé¡µæ•°æ®

ä»»åŠ¡ï¼š
æ¨¡æ‹Ÿçˆ¬å–å¤šé¡µæ•°æ®ï¼Œæå–æ‰€æœ‰é¡µé¢çš„ä¿¡æ¯
"""

def exercise_8_pagination():
    """
    ç»ƒä¹ 8ï¼šç¿»é¡µçˆ¬å–ï¼ˆæ¨¡æ‹Ÿï¼‰

    TODO: å®Œæˆä¸‹é¢çš„ä»£ç 
    """
    from bs4 import BeautifulSoup
    import json
    import os
    import time
    import random

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 8ï¼šç¿»é¡µçˆ¬å–ï¼ˆæ¨¡æ‹Ÿï¼‰")
    print("=" * 40)

    # æ¨¡æ‹Ÿ3é¡µæ•°æ®
    pages = [
        """<div class="items"><span class="item">ç¬¬1é¡µ-é¡¹ç›®A</span></div>""",
        """<div class="items"><span class="item">ç¬¬2é¡µ-é¡¹ç›®B</span></div>""",
        """<div class="items"><span class="item">ç¬¬3é¡µ-é¡¹ç›®C</span></div>""",
    ]

    all_items = []

    # TODO: å¾ªç¯å¤„ç†æ¯ä¸€é¡µ
    for i, page_html in enumerate(pages, 1):
        print(f"å¤„ç†ç¬¬ {i} é¡µ...")

        # TODO: è§£æå½“å‰é¡µ
        soup = BeautifulSoup(page_html, 'html.parser')
        items = soup.find_all('span', class_='item')

        # TODO: æå–æ•°æ®
        for item in items:
            all_items.append(item.text)
            print(f"  æå–: {item.text}")

        # æ¨¡æ‹Ÿå»¶è¿Ÿï¼ˆå®é™…çˆ¬è™«éœ€è¦ï¼‰
        # time.sleep(random.uniform(1, 2))

    print(f"\nâœ… å…±æå– {len(all_items)} æ¡æ•°æ®")
    print(f"æ‰€æœ‰æ•°æ®: {all_items}")


def answer_8_pagination():
    """
    ç»ƒä¹ 8ç­”æ¡ˆ
    """
    from bs4 import BeautifulSoup
    import json
    import os
    import time
    import random

    print("\n" + "=" * 40)
    print("ç»ƒä¹ 8ç­”æ¡ˆ")
    print("=" * 40)

    # æ¨¡æ‹Ÿ3é¡µæ•°æ®ï¼ˆå®é™…ä¸­æ˜¯é€šè¿‡è¯·æ±‚ä¸åŒURLè·å–çš„ï¼‰
    pages = [
        """<div class="items"><span class="item">ç¬¬1é¡µ-é¡¹ç›®A</span></div>""",
        """<div class="items"><span class="item">ç¬¬2é¡µ-é¡¹ç›®B</span></div>""",
        """<div class="items"><span class="item">ç¬¬3é¡µ-é¡¹ç›®C</span></div>""",
    ]

    all_items = []

    # å¾ªç¯å¤„ç†æ¯ä¸€é¡µ
    for i, page_html in enumerate(pages, 1):
        print(f"å¤„ç†ç¬¬ {i} é¡µ...")

        # è§£æå½“å‰é¡µ
        soup = BeautifulSoup(page_html, 'html.parser')

        # æå–æ•°æ®
        items = soup.find_all('span', class_='item')
        for item in items:
            all_items.append(item.text)
            print(f"  æå–: {item.text}")

        # æ¨¡æ‹Ÿå»¶è¿Ÿï¼ˆå®é™…çˆ¬è™«ä¸­å¿…é¡»æœ‰ï¼‰
        delay = random.uniform(0.1, 0.3)  # æ¼”ç¤ºç”¨è¾ƒçŸ­å»¶è¿Ÿ
        time.sleep(delay)

    print(f"\nâœ… å…±æå– {len(all_items)} æ¡æ•°æ®")
    print(f"æ‰€æœ‰æ•°æ®: {all_items}")

    print("\nâœ… ç­”æ¡ˆè¯´æ˜ï¼š")
    print("1. ä½¿ç”¨å¾ªç¯å¤„ç†å¤šé¡µ")
    print("2. æ¯é¡µéƒ½è¦è§£æå’Œæå–æ•°æ®")
    print("3. å°†æ‰€æœ‰æ•°æ®åˆå¹¶åˆ°ä¸€èµ·")
    print("4. å®é™…çˆ¬è™«ä¸­è¦æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«")


# ============================================================
# è¿è¡Œæ‰€æœ‰ç»ƒä¹ 
# ============================================================
def run_all_exercises():
    """è¿è¡Œæ‰€æœ‰ç»ƒä¹ é¢˜"""
    print("\n" + "ğŸ“" * 20)
    print("è¿è¡Œæ‰€æœ‰ç»ƒä¹ é¢˜...")
    print("ğŸ“" * 20)

    exercise_1_request()
    exercise_2_params()
    exercise_3_parse()
    exercise_4_selector()
    exercise_5_csv()
    exercise_6_json()
    exercise_7_complete()
    exercise_8_pagination()

    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ç»ƒä¹ å®Œæˆï¼")
    print("=" * 60)


def run_all_answers():
    """è¿è¡Œæ‰€æœ‰ç­”æ¡ˆ"""
    print("\n" + "ğŸ“–" * 20)
    print("è¿è¡Œæ‰€æœ‰ç­”æ¡ˆ...")
    print("ğŸ“–" * 20)

    answer_1_request()
    answer_2_params()
    answer_3_parse()
    answer_4_selector()
    answer_5_csv()
    answer_6_json()
    answer_7_complete()
    answer_8_pagination()

    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ç­”æ¡ˆå±•ç¤ºå®Œæˆï¼")
    print("=" * 60)


# ============================================================
# ä¸»ç¨‹åºå…¥å£
# ============================================================
if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                          â•‘
â•‘              ğŸ“ ç½‘ç»œçˆ¬è™«ç»ƒä¹ é¢˜  ğŸ“                       â•‘
â•‘                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€ç»ƒä¹ åˆ—è¡¨ã€‘
1. å‘é€HTTPè¯·æ±‚
2. å¸¦å‚æ•°çš„è¯·æ±‚
3. è§£æHTML
4. CSSé€‰æ‹©å™¨
5. ä¿å­˜æ•°æ®åˆ°CSV
6. ä¿å­˜æ•°æ®åˆ°JSON
7. å®Œæ•´çˆ¬è™«
8. ç¿»é¡µçˆ¬å–

ã€ä½¿ç”¨æ–¹æ³•ã€‘
1. è¿è¡Œç»ƒä¹ é¢˜ï¼šexercise_1_request()
2. æŸ¥çœ‹ç­”æ¡ˆï¼šanswer_1_request()
3. è¿è¡Œæ‰€æœ‰ç»ƒä¹ ï¼šrun_all_exercises()
4. æŸ¥çœ‹æ‰€æœ‰ç­”æ¡ˆï¼šrun_all_answers()

ã€å»ºè®®ã€‘
- å…ˆè‡ªå·±å®Œæˆç»ƒä¹ ï¼Œå†çœ‹ç­”æ¡ˆ
- æ¯ä¸ªç»ƒä¹ éƒ½æœ‰è¯¦ç»†è¯´æ˜
    """)

    # æç¤ºç”¨æˆ·è¾“å…¥
    print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
    print("1. è¿è¡Œæ‰€æœ‰ç»ƒä¹ ")
    print("2. æŸ¥çœ‹æ‰€æœ‰ç­”æ¡ˆ")
    print("3. è¿è¡Œå•ä¸ªç»ƒä¹ ï¼ˆè¾“å…¥ç»ƒä¹ ç¼–å·1-8ï¼‰")
    print("4. æŸ¥çœ‹å•ä¸ªç­”æ¡ˆï¼ˆè¾“å…¥ç­”æ¡ˆç¼–å·1-8ï¼‰")
    print("5. é€€å‡º")

    choice = input("\nè¯·è¾“å…¥é€‰é¡¹: ").strip()

    if choice == '1':
        run_all_exercises()
    elif choice == '2':
        run_all_answers()
    elif choice in ['1', '2', '3', '4', '5', '6', '7', '8']:
        # è¿è¡Œå•ä¸ªç»ƒä¹ æˆ–ç­”æ¡ˆ
        num = choice
        if input("æŸ¥çœ‹ç­”æ¡ˆï¼Ÿ(y/n): ").lower() == 'y':
            exec(f"answer_{num}_*" + "{" + "*"[0] + "}" + "()")
        else:
            exec(f"exercise_{num}_*" + "{" + "*"[0] + "}" + "()")
    else:
        print("å†è§ï¼ç»§ç»­åŠ æ²¹å­¦ä¹ ï¼")
