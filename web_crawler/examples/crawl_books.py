# -*- coding: utf-8 -*-
"""
ç¤ºä¾‹3ï¼šçˆ¬å–ä¹¦ç±ä¿¡æ¯
====================

ç›®æ ‡ç½‘ç«™ï¼šhttp://books.toscrape.com
è¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºå­¦ä¹ çˆ¬è™«çš„åœ¨çº¿ä¹¦åº—

çˆ¬å–å†…å®¹ï¼š
- ä¹¦å
- ä»·æ ¼
- è¯„åˆ†
- æ˜¯å¦æœ‰åº“å­˜
- å°é¢å›¾ç‰‡é“¾æ¥

è¿è¡Œæ–¹æ³•ï¼š
python crawl_books.py
"""

import requests
from bs4 import BeautifulSoup
import csv
import json
import time
import random
import os
import re


def get_headers():
    """
    è·å–éšæœºè¯·æ±‚å¤´

    è¿”å›å€¼ï¼š
        dict: è¯·æ±‚å¤´å­—å…¸
    """
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    ]
    return {
        "User-Agent": random.choice(user_agents),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
    }


def parse_price(price_str):
    """
    è§£æä»·æ ¼å­—ç¬¦ä¸²

    å‚æ•°è¯´æ˜ï¼š
        price_str (str): ä»·æ ¼å­—ç¬¦ä¸²ï¼Œå¦‚ "Â£25.99"

    è¿”å›å€¼ï¼š
        float: ä»·æ ¼æ•°å€¼
    """
    # æå–æ•°å­—éƒ¨åˆ†
    match = re.search(r'[\d.]+', price_str)
    if match:
        return float(match.group())
    return 0.0


def parse_rating(rating_class):
    """
    è§£æè¯„åˆ†

    å‚æ•°è¯´æ˜ï¼š
        rating_class (str): è¯„åˆ†classåï¼Œå¦‚ "Three"

    è¿”å›å€¼ï¼š
        int: è¯„åˆ†æ•°å€¼ï¼ˆ1-5ï¼‰
    """
    rating_map = {
        "One": 1, "Two": 2, "Three": 3, "Four": 4, "Five": 5
    }
    for key, value in rating_map.items():
        if key in rating_class:
            return value
    return 0


def parse_availability(availability_str):
    """
    è§£æåº“å­˜çŠ¶æ€

    å‚æ•°è¯´æ˜ï¼š
        availability_str (str): åº“å­˜å­—ç¬¦ä¸²

    è¿”å›å€¼ï¼š
        bool: æ˜¯å¦æœ‰åº“å­˜
    """
    return "In stock" in availability_str


def crawl_books(max_pages=2):
    """
    çˆ¬å–ä¹¦ç±ä¿¡æ¯

    å‚æ•°è¯´æ˜ï¼š
        max_pages (int): æœ€å¤§çˆ¬å–é¡µæ•°ï¼Œé»˜è®¤2é¡µ

    è¿”å›å€¼ï¼š
        list: ä¹¦ç±åˆ—è¡¨

    è°ƒç”¨ç¤ºä¾‹ï¼š
        books = crawl_books(5)  # çˆ¬å–5é¡µ
        books = crawl_books()   # çˆ¬å–2é¡µï¼ˆé»˜è®¤ï¼‰
    """
    print("=" * 60)
    print("ğŸ“š å¼€å§‹çˆ¬å–ä¹¦ç±ä¿¡æ¯")
    print("=" * 60)
    print(f"ç›®æ ‡: http://books.toscrape.com")
    print(f"è®¡åˆ’çˆ¬å–: {max_pages} é¡µ")
    print("-" * 60)

    base_url = "http://books.toscrape.com/catalogue/page-{}.html"
    all_books = []

    for page in range(1, max_pages + 1):
        url = base_url.format(page)
        print(f"\nğŸ“– æ­£åœ¨çˆ¬å–ç¬¬ {page} é¡µ: {url}")

        try:
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            delay = random.uniform(1, 2)
            time.sleep(delay)

            # å‘é€è¯·æ±‚
            headers = get_headers()
            response = requests.get(url, headers=headers, timeout=10)

            if response.status_code != 200:
                print(f"  âŒ çŠ¶æ€ç : {response.status_code}")
                continue

            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')

            # æ‰¾åˆ°æ‰€æœ‰ä¹¦ç±
            books = soup.find_all('article', class_='product_pod')
            print(f"  æ‰¾åˆ° {len(books)} æœ¬ä¹¦")

            for book in books:
                # æå–ä¹¦å
                title_element = book.find('h3').find('a')
                title = title_element['title'] if title_element else "æœªçŸ¥"

                # æå–ä»·æ ¼
                price_element = book.find('p', class_='price_color')
                price_str = price_element.text if price_element else "Â£0.00"
                price = parse_price(price_str)

                # æå–è¯„åˆ†
                rating_element = book.find('p', class_='star-rating')
                rating_class = str(rating_element['class']) if rating_element else ""
                rating = parse_rating(rating_class)

                # æå–åº“å­˜
                availability_element = book.find('p', class_='instock availability')
                availability_str = availability_element.text.strip() if availability_element else ""
                in_stock = parse_availability(availability_str)

                # æå–å›¾ç‰‡é“¾æ¥
                img_element = book.find('img')
                img_src = img_element['src'] if img_element else ""
                # è½¬æ¢ä¸ºå®Œæ•´URL
                img_url = "http://books.toscrape.com/" + img_src if img_src else ""

                # ä¿å­˜æ•°æ®
                book_data = {
                    'title': title,
                    'price': price,
                    'price_str': price_str,
                    'rating': rating,
                    'in_stock': in_stock,
                    'img_url': img_url
                }
                all_books.append(book_data)

                # æ˜¾ç¤º
                stock_icon = "âœ…" if in_stock else "âŒ"
                star = "â­" * rating
                print(f"  {stock_icon} ã€Š{title[:30]}...ã€‹ {price_str} {star}")

        except requests.exceptions.ConnectionError:
            print("  âŒ ç½‘ç»œè¿æ¥å¤±è´¥")
            break
        except Exception as e:
            print(f"  âŒ çˆ¬å–å¤±è´¥: {e}")
            continue

    print("\n" + "=" * 60)
    print(f"ğŸ‰ çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_books)} æœ¬ä¹¦")
    print("=" * 60)

    return all_books


def show_statistics(books):
    """
    æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯

    å‚æ•°è¯´æ˜ï¼š
        books (list): ä¹¦ç±åˆ—è¡¨
    """
    if not books:
        return

    print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    print("-" * 40)

    # ä»·æ ¼ç»Ÿè®¡
    prices = [b['price'] for b in books]
    print(f"ä»·æ ¼ç»Ÿè®¡:")
    print(f"  - æœ€ä½ä»·: Â£{min(prices):.2f}")
    print(f"  - æœ€é«˜ä»·: Â£{max(prices):.2f}")
    print(f"  - å¹³å‡ä»·: Â£{sum(prices)/len(prices):.2f}")

    # è¯„åˆ†ç»Ÿè®¡
    ratings = [b['rating'] for b in books]
    rating_counts = {}
    for r in ratings:
        rating_counts[r] = rating_counts.get(r, 0) + 1

    print(f"\nè¯„åˆ†åˆ†å¸ƒ:")
    for rating in sorted(rating_counts.keys(), reverse=True):
        count = rating_counts[rating]
        bar = "â– " * count
        print(f"  {rating}æ˜Ÿ: {count}æœ¬ {bar}")

    # åº“å­˜ç»Ÿè®¡
    in_stock = sum(1 for b in books if b['in_stock'])
    print(f"\nåº“å­˜æƒ…å†µ:")
    print(f"  - æœ‰åº“å­˜: {in_stock}æœ¬")
    print(f"  - æ— åº“å­˜: {len(books) - in_stock}æœ¬")


def filter_books(books, **filters):
    """
    ç­›é€‰ä¹¦ç±

    å‚æ•°è¯´æ˜ï¼š
        books (list): ä¹¦ç±åˆ—è¡¨
        filters (dict): ç­›é€‰æ¡ä»¶
            - min_price: æœ€ä½ä»·æ ¼
            - max_price: æœ€é«˜ä»·æ ¼
            - min_rating: æœ€ä½è¯„åˆ†
            - in_stock_only: åªæ˜¾ç¤ºæœ‰åº“å­˜

    è¿”å›å€¼ï¼š
        list: ç­›é€‰åçš„ä¹¦ç±åˆ—è¡¨

    è°ƒç”¨ç¤ºä¾‹ï¼š
        # ç­›é€‰ä»·æ ¼ä½äº30çš„ä¹¦
        cheap_books = filter_books(books, max_price=30)

        # ç­›é€‰5æ˜Ÿè¯„åˆ†çš„ä¹¦
        top_books = filter_books(books, min_rating=5)

        # ç­›é€‰æœ‰åº“å­˜çš„ä¾¿å®œä¹¦
        result = filter_books(books, max_price=20, in_stock_only=True)
    """
    result = books

    if 'min_price' in filters:
        result = [b for b in result if b['price'] >= filters['min_price']]

    if 'max_price' in filters:
        result = [b for b in result if b['price'] <= filters['max_price']]

    if 'min_rating' in filters:
        result = [b for b in result if b['rating'] >= filters['min_rating']]

    if filters.get('in_stock_only'):
        result = [b for b in result if b['in_stock']]

    return result


def save_to_csv(data, filepath):
    """
    ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶

    å‚æ•°è¯´æ˜ï¼š
        data (list): æ•°æ®åˆ—è¡¨
        filepath (str): ä¿å­˜è·¯å¾„
    """
    if not data:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
        return

    with open(filepath, 'w', newline='', encoding='utf-8') as f:
        fieldnames = ['title', 'price', 'price_str', 'rating', 'in_stock', 'img_url']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)

    print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {filepath}")


def save_to_json(data, filepath):
    """
    ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶

    å‚æ•°è¯´æ˜ï¼š
        data (list): æ•°æ®åˆ—è¡¨
        filepath (str): ä¿å­˜è·¯å¾„
    """
    if not data:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
        return

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {filepath}")


def main():
    """
    ä¸»å‡½æ•°
    """
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                          â•‘
â•‘           ğŸ“š ä¹¦ç±ä¿¡æ¯çˆ¬è™«  ğŸ“š                            â•‘
â•‘                                                          â•‘
â•‘           ç›®æ ‡: http://books.toscrape.com                â•‘
â•‘                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = "/mnt/c/dev/python/qqstudy/web_crawler/data"
    os.makedirs(save_dir, exist_ok=True)

    # è·å–ç”¨æˆ·è¾“å…¥
    try:
        pages = input("è¯·è¾“å…¥è¦çˆ¬å–çš„é¡µæ•°ï¼ˆç›´æ¥å›è½¦é»˜è®¤2é¡µï¼‰: ").strip()
        max_pages = int(pages) if pages else 2
    except ValueError:
        max_pages = 2

    # çˆ¬å–æ•°æ®
    books = crawl_books(max_pages)

    if books:
        # æ˜¾ç¤ºç»Ÿè®¡
        show_statistics(books)

        # ä¿å­˜æ•°æ®
        csv_file = os.path.join(save_dir, "books.csv")
        json_file = os.path.join(save_dir, "books.json")

        save_to_csv(books, csv_file)
        save_to_json(books, json_file)

        # ç­›é€‰ç¤ºä¾‹
        print("\n" + "=" * 60)
        print("ğŸ” ç­›é€‰ç¤ºä¾‹")
        print("=" * 60)

        # ç­›é€‰5æ˜Ÿä¹¦ç±
        top_books = filter_books(books, min_rating=5)
        print(f"\n5æ˜Ÿè¯„åˆ†ä¹¦ç±ï¼ˆå…±{len(top_books)}æœ¬ï¼‰:")
        for book in top_books[:5]:
            print(f"  - ã€Š{book['title'][:40]}ã€‹")

        # ç­›é€‰ä¾¿å®œä¹¦ç±
        cheap_books = filter_books(books, max_price=20)
        print(f"\nä»·æ ¼ä½äºÂ£20çš„ä¹¦ç±ï¼ˆå…±{len(cheap_books)}æœ¬ï¼‰:")
        for book in cheap_books[:5]:
            print(f"  - ã€Š{book['title'][:40]}ã€‹ Â£{book['price']:.2f}")

    print("\n" + "=" * 60)
    print("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæ¯•ï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
